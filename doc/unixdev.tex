
\magnification\magstep1
\input fixpdfmag % for pdftex
\input epsf % for including *.mps figures
\input fonts % font size switching

\hsize 15 true cm \advance\hoffset 5 true mm
\vsize 24 true cm \advance\voffset 1 true mm

\parskip=1pt plus 1pt
\parindent=2pc

\font\tfone=cmssbx12 scaled\magstep2
\font\tftwo=cmss12 scaled\magstephalf
\font\headingfont=cmssbx12
\font\sans=cmss10
\font\sc=cmr9 % small caps (relative to cmr10)

\def\section #1\par{\vskip 0pt plus .1\vsize\penalty-250
  \vskip 0pt plus -.1\vsize \vskip 24pt plus 6pt minus 4pt
  \vskip\parskip \leftline{\headingfont #1}%
  \nobreak\medskip\noindent\ignorespaces}

\def\subsect #1.{\bigbreak\noindent{\bf #1.\enspace}\ignorespaces}
\def\exercise #1.{\bigbreak\begingroup\ninepoint
  \noindent{\bf Exercise #1.\enspace}\ignorespaces}
\def\endexercise{\unskip\kern.8ex$\sqcup\mkern-12mu\sqcap$\par\endgroup}

\def\begincode{\medbreak\begingroup\tt
  \obeylines\obeyspaces\frenchspacing
  \spaceskip=\ttglue \baselineskip=11pt plus.5pt
  \catcode`\$=12\catcode`\{=12\catcode`\}=12\catcode`\&=12
  \catcode`\^=12\catcode`\#=12\catcode`\%=12\catcode`\_=12\relax}%
\def\endcode{\medskip\endgroup}

\def\0{\phantom{0}}% to align numbers
\def\\{\char"5C\relax}% backslash in cmtt font
\def\ocb{\char"7B\relax}% opening curly brace in cmtt
\def\ccb{\char"7D\relax}% closing curly brace in cmtt


\topglue 0pc\noindent
Excerpt from {\sl The UNIX Programming Environment}
by Brian W.~Kernighan and Rob Pike,
Prentice-Hall Software Series, 1984.
Copyright 1984 by Bell Telephone Laboratories, Incorporated.
Minimally edited to conform to {\sc ANSI}~C.
\vskip 4pc plus 1pc

\centerline{\tftwo Chapter 8}
\bigskip
\centerline{\tfone PROGRAM DEVELOPMENT}
\medskip
\centerline{\tftwo in the Unix Programming Environment}
\vskip 2pc plus 1pc

\noindent
The {\sc UNIX} system was originally meant as a program development
environment. In this chapter we'll talk about some of the tools that
are particularly suited for developing programs. Our vehicle is a
substantial program, an interpreter for a programming language
comparable in power to {\sc BASIC}. We chose to implement a language
because it's representative of problems encountered in large
programs. Furthermore, many programs can profitably be viewed as
languages that convert a systematic input into a sequence of actions
and outputs, so we want to illustrate the language development tools.

In this chapter, we will cover specific lessons about
\item{--} {\tt yacc}, a parser generator, a program that generates
a parser from a grammatical description of a language;
\item{--} {\tt make}, a program for specifying and controlling the
process by which a complicated program is compiled;
\item{--} {\tt lex}, a program analogous to {\tt yacc}, for making
 lexical analyzers.
\par\noindent
We also want to convey some notions of how to go about such a
project---the importance of starting with something small and letting
it grow; language evolution; and the use of tools.

We will describe the implementation of the language in six stages,
each of which would be useful even if the development went no further.
These stages closely parallel the way that we actually wrote the
program.

\smallskip\item{(1)}
A four-function calculator, providing {\tt + - * /} and parentheses,
that operates on floating point numbers. One expression is typed on
each line; its value is printed immediately.

\smallskip\item{(2)}
Variables with names {\tt a} through {\tt z}. This version also has
unary minus and some defenses against errors.

\smallskip\item{(3)}
Arbitrarily-long variable names, built-in functions for {\tt sin},
{\tt exp}, etc., useful constants like $\pi$ (spelled {\tt PI}
because of typographic limitations), and an exponentiation operator.

\smallskip\item{(4)}
A change in internals: code is generated for each statement and
subsequently interpreted, rather than being evaluated on the fly.
No new features are added, but it leads to~(5).

\smallskip\item{(5)}
Control flow: {\tt if}-{\tt else} and {\tt while}, statement
grouping with {\tt\ocb} and {\tt\ccb}, and relational operators
like {\tt>}, {\tt<=}, etc.

\smallskip\item{(6)}
Recursive functions and procedures, with arguments. We also added
statements for input and for output of strings as well as numbers.

\smallskip\noindent
The resulting language is described in Chapter~9, where it serves
as the main example in our presentation of the {\sc UNIX} document
preparation software. Appendix~2 is the reference manual.

This is a very long chapter, because there's a lot of detail involved
in getting a non-trivial program written correctly, let alone presented.
We are assuming that you understand~C, and that you have a copy of the
{\sl Unix Programmer's Manual,} Volume~2, close at hand, since we
simply don't have space to explain every nuance. Hang in, and be
prepared to read the chapter a couple of times. We have also included
all of the code for the final version in Appendix~3, so you can see
more easily how the pieces fit together.

By the way, we wasted a lot of time debating names for this language
but never came up with anything satisfactory. We settled on {\tt hoc},
which stands for ``high-order calculator.'' The versions are thus
{\tt hoc1}, {\tt hoc2}, etc.


\section Stage 1: A four-function calculator

This section describes the implementation of {\tt hoc1}, a program
that provides about the same capabilities as a minimal pocket
calculator. It has only four
functions: {\tt+}, {\tt-}, {\tt*}, and {\tt/}, but it does have
parentheses that can be nested arbirarily deeply, which few pocket
calculators provide. If you type an expression followed by
{\sc RETURN}, the anwer will be printed on the next line:

\begincode
$ hoc1
4*3*2
~       24
(1+2) * (3+4)
~       21
1/2
~       0.5
355/113
~       3.1415929
-3-4
hoc1: syntax error near line 4\quad\it It doesn't have unary minus yet
\tt$
\endcode

\subsect Grammars.
Ever since Backus-Naur Form was developed for Algol, languages have
been described by formal grammars. The grammar for {\tt hoc1} is small
and simple in its abstract representation:

\medbreak
\indent\indent\vbox{\halign{\tabskip1em\tt#\hfil&\tt#\hfil\cr
 list:& expr \\n\cr
      & list expr \\n\cr
 expr:& NUMBER\cr
      & expr + expr\cr
      & expr - expr\cr
      & expr * expr\cr
      & expr / expr\cr
      & ( expr )\cr}}
\medskip
\noindent
In other words, a {\tt list} is a sequence of expressions, each
followed by a newline. An expression is a number, or a pair of
expressions joined by an operator, or a pharenthesized expression.

This is not complete. Among other things, it does not specify
the normal precedence and associativity of the operators, nor
does it attach a meaning to any construct. And although {\tt list}
is defined in terms of {\tt expr}, and {\tt expr} is defined in
terms of {\tt NUMBER}, {\tt NUMBER} itself is nowhere defined.
These details have to be filled in to go from a sketch of the
language to a working program.

\subsect Overview of yacc.
{\tt yacc} is a {\it parser generator},\footnote{$\dag$}{{\tt yacc}
stands for ``yet another compiler-compiler,'' a comment by its
creator, Steve Johnson, on the number of such programs extant
at the time it was being developed (around 1972). {\tt yacc}
is one of a handful that have flourished.} that is, a program
for converting a grammatical specification of a language like
the one above into a parser that will parse statements in the
language. {\tt yacc} provides a way to associate meanings with
the components of the grammar in such a way that as the parsing
takes place, the meaning can be ``evaluated'' as well. The stages
in using {\tt yacc} are the following.

First, a grammar is written, like the one above, but more precise.
This specifies the syntax of the language. {\tt yacc} can be used
at this stage to warn of errors and ambiguities in the grammar.

Second, each rule or {\it production\/} of the grammar can be
augmented with an {\it action}---a statement of what to do
when an instance of that grammatical form is found in a program
being parsed. The ``what to do'' part is written in~C, with
conventions for connecting the grammar to the C~code.
This defines the semantics of the language.

Third, a {\it lexical scanner\/} is needed, which will read
the input being parsed and break it up into meaningful chunks
for the parser. A {\tt NUMBER} is an example of a lexical
chunk that is several characters long; single-character operators
like {\tt+} and {\tt*} are also chunks. A lexical chunk is called
a {\it token}.

Finally, a controlling routine is needed, to call the parser
that {\tt yacc} built.

{\tt yacc} proceses the grammar and the semantic actions into
a parsing function, named {\tt yyparse}, and writes it out as
a file of C~code. If {\tt yacc} finds no errors, the parser,
the lexical analyzer, and the control routines can be compiled,
perhaps linked with other C~routines, and executed. The operation
of this program is to call repeatedly upon the lexical analyzer
for tokens, recognize the grammatical (syntactic) structure in the
input, and perform the semantic actions as each grammatical rule
is recognized. The entry to the lexical analyzer must be named
{\tt yylex}, since that is the function that {\tt yyparse} calls
each time it wants another token. (All names used by {\tt yacc}
start with~y.)

To be somewhat more precise, the input to {\tt yacc} takes
this form:

\begincode
%{
\it C statements like \tt#include\it, declarations, etc. This section is optional\tt
%}
\begingroup\it yacc declarations: lexical tokens, grammar variables,
\quad precedence and associativity information\endgroup
%%
\begingroup\it grammar rules and actions\endgroup
%%
\begingroup\it more C statements (optional):\endgroup
main() { ...; yyparse(); ... }
yylex() { ... }
...
\endcode

\noindent
This is processed by {\tt yacc} and the result is written into
a file called {\tt y.tab.c}, whose layout is like this:

\smallbreak
\begingroup
\obeylines
{\it C statements from between {\tt\%\ocb} and {\tt\%\ccb}, if any}
{\it C statements from after second {\tt\%\%}, if any:}
{\tt main() \ocb\ ...; yyparse(); ... \ccb}
{\tt yylex() \ocb\ ... \ccb}
...
{\tt yyparse() \ocb\ \it parser, which calls \tt yylex() \ccb}
\endgroup
\smallskip

It is typical of the {\sc UNIX} approach that {\tt yacc} produces
C instead of a compiled object ({\tt.o}) file. This is the most
flexible arrangement---the generated code is portable and amenable
to other processing whenever someone has a good idea.

{\tt yacc} itself is a powerful tool. It takes some effort to learn,
but the effort is repaid many times over. {\tt yacc}-generated parsers
are small, efficient, and correct (though the semantic actions are
your own responsibility); many nasty parsing problems are taken
care of automatically. Language-recognizing programs are easy
to build, and (probably more important) can be modified repeatedly
as the language definition evolves.

\subsect Stage 1 program.
The source code for {\tt hoc1} consists of a grammar with actions,
a lexical routine {\tt yylex}, and a {\tt main}, all in one file
{\tt hoc.y}. ({\tt yacc} filenames traditionally end in {\tt.y},
but this convention is not enforced by {\tt yacc} itself, unlike
{\tt cc} with {\tt.c} files) The grammar part is the first half of
{\tt hoc.y}:

\begincode
%{
#include <stdio.h>      \it includes needed for code later on\tt
#include <ctype.h>
#define YYSTYPE double   /* data type of yacc stack */
%}
\smallbreak
%token  NUMBER
%left   '+' '-'   /* left associative, same precedence */
%left   '*' '/'   /* left associative, higher precedence */
\smallbreak
%%
list:     /* nothing */
~       | list '\\n'
~       | list expr '\\n'  { printf("\\t%.8g\\n", $2); }
~       ;
expr:     NUMBER          { $$ = $1; }
~       | expr '+' expr   { $$ = $1 + $3; }
~       | expr '-' expr   { $$ = $1 - $3; }
~       | expr '*' expr   { $$ = $1 * $3; }
~       | expr '/' expr   { $$ = $1 / $3; }
~       | '(' expr ')'    { $$ = $2; }
~       ;
%%
~       /* end of grammar */
...
\endcode

There's a lot of new information packed into these few lines.
We are not going to explain all of it, and certainly not how
the parser works---for that, you will have to read the {\tt yacc}
manual.

Alternate rules are separated by `{\tt|}'. Any grammar rule can
have an associated action, which will be performed when an instance
of that rule is recognized in the input. An action is a sequence
of C statements enclosed in braces {\tt\ocb} and {\tt\ccb}.
Within an action, {\tt\$\it n\/} (that is, {\tt\$1}, {\tt\$2}, etc.)
refers to the value returned by the $n$th component of the rule,
and {\tt\$\$} is the value to be returned as the value of the
whole rule. So for example, in the rule
\begincode
expr:  NUMBER  { $$ = $1; }
\endcode
\noindent
{\tt\$1} is the value returned by recognizing {\tt NUMBER};
that value is to be returned as the value of the {\tt expr}.
The particular assignment {\tt\$\$=\$1} can be omitted---{\tt\$\$}
is always set to {\tt\$1} unless you explicitly set it to something
else.

At the next level, when the rule is
\begincode
expr:  expr '+' expr  { $$ = $1 + $3; }
\endcode
\noindent
the value of the result {\tt expr} is the sum of the values from
the two component {\tt expr}'s. Notice that {\tt'+'} is {\tt\$2};
every component is numbered.

At the level above this, an expressoin followed by a newline
{\tt'\\n'} is recognized as a list and its value is printed.
If the end of the input follows such a construction, the parsing
process terminates cleanly. A {\tt list} can be an empty string;
this is how blank input lines are handled.

{\tt yacc} input is free form; our format is the recommended standard.

In this implementation, the act of recognizing or parsing the input
also causes immediate evaluation of the expression. In more
complicated situations (including {\tt hoc4} and its successors),
the parsing process generates code for later execution.

You may find it helpful to visualize parsing as drawing a
{\it parse tree\/} like the one in the figure, and to imaginge
values being computed and propagated up the tree from the leaves
towards the root.
\medskip
\centerline{\epsfbox{unixdev-1.mps}}
\centerline{Parse Tree for {\tt 2 + 3 * 4}}
\medskip
\noindent
The values of incompletely-recognized rules are actually kept
on a stack; this is how the values are passed from one rule
to the next. The data type of this stack is normally an {\tt int},
but since we are processing floating point numbers, we have to
override the default. The definition
\begincode
#define YYSTYPE double
\endcode\noindent
sets the stack type to {\tt double}.

Syntactic classes that will be recognized by the lexical analyzer
have to be declared unless they are single character literals like
{\tt+} and~{\tt-}. The declaration {\tt\%token} declares one or
more such objects. Left or right associativity can be specified
if appropriate by using {\tt\%left} or {\tt\%right} instead of
{\tt\%token}. (Left associativity means that {\tt a-b-c} will
be parsed as {\tt(a-b)-c} instead of {\tt a-(b-c)}.)
Precedence is determined by order of appearance: tokens
in the same declaration are at the same level of precedence;
tokens declared later are of higher precedence. In this way
the grammar proper is ambiguous (that is, there are multiple
ways to parse some inputs), but the extra information in the
declarations resolves the ambiguity.

The rest of the code is the routines in the second half of the
file {\tt hoc.y}:
\begincode
~                       \it Continuing\/\tt hoc.y
char    *progname;       /* for error messages */
int     lineno = 1;
\medskip
int main(int argc, char *argv[])   /* hoc1 */
{
~       progname = argv[0];
~       yyparse();
~       return 0;
}
\endcode
\noindent
{\tt main} calls {\tt yyparse} to parse the input. Looping from
one expression to the next is done entirely within the grammar,
by the sequence of productions for {\tt list}. It would have been
equally acceptable to put a loop around the call to {\tt yyparse}
in {\tt main} and have the action for {\tt list} print the value
and return immediately.

{\tt yyparse} in turn calls {\tt yylex} repeatedly for input
tokens. Our {\tt yylex} is easy: it skips blanks and tabs,
converts strings of digits into a numeric value, counts input
lines for error reporting, and returns any other character as
itself.
Since the grammar expects to see only {\tt+}, {\tt-}, {\tt*},
{\tt/}, {\tt(}, {\tt)}, and {\tt\\n}, any other character
will cause {\tt yyparse} to report an error. Returning a {\tt0}
signals ``end of file'' to {\tt yyparse}.
\begincode
~                       \it Continuing\/\tt hoc.y
int yylex(void)          /* hoc1 */
{
~       int c;
\smallskip
~       while ((c=getchar()) == ' ' || c == '\\t')
~               ;
~       if (c == EOF)
~               return 0;
~       if (c == '.' || isdigit(c)) {   /* number */
~               ungetc(c, stdin);
~               scanf("%lf", &yylval);
~               return NUMBER;
~       }
~       if (c == '\\n')
~               lineno++;
~       return c;
}
\endcode
\noindent
The variable {\tt yylval} is used for communication between
the parser and the lexical analyzer; it is defined by {\tt yyparse},
and has the same type as the {\tt yacc} stack. {\tt yylex} returns
the {\it type\/} of a token as its function value, and sets
{\tt yylval} to the {\it value\/} of the token (if there is one).
For instance, a floating point number has the type {\tt NUMBER}
and a value like 12.34. For some tokens, especially single
characters like {\tt'+'} and {\tt'\\n'}, the grammar does not use
the value, only the type. In that case, {\tt yylval} need not be set.

The {\tt yacc} declaration {\tt\%token NUMBER} is converted into
a {\tt\#define} statement in the {\tt yacc} output file {\tt y.tab.c},
so {\tt NUMBER} can be used as a constant anywhere in the C program.
{\tt yacc} chooses values that won't collide with {\sc ASCII} characters.

If there is a syntax error, {\tt yyparse} calls {\tt yyerror} with
a string containing the cryptic message ``{\tt syntax error}.''
The {\tt yacc} user is expected to provide a {\tt yyerror}; ours
just passes the string on to another function, {\tt warning},
which prints somewhat more information. Later versions of {\tt hoc}
will make direct use of {\tt warning}.

\begincode
void yyerror(char *s)  /* called for yacc syntax error */
{
~       warning(s, 0);
}
\medbreak
void warning(char *s, char *t)  /* print warning message */
{
~       fprintf(stderr, "%s: %s", progname, s);
~       if (t) fprintf(stderr, " %s", t);
~       fprintf(stderr, " near line %d\\n", lineno);
}
\endcode

\noindent
This marks the end of the routines in {\tt hoc.y}.

Compilation of a {\tt yacc} program is a two-step process:
\begincode
$ yacc hoc.y            \it Leaves output in \tt y.tab.c
$ cc y.tab.c -o hoc1    \it Leaves executable program in \tt hoc1
$ hoc1
2/3
~       0.66666667
-3-4
hoc1: syntax error near line 1
$
\endcode

\exercise 8-1.
Examine the structure of the {\tt y.tab.c} file.
%(It's about 300 lines long for {\tt hoc1}.)
\endexercise

\subsect Making changes---unary minus.
We claimed earlier that using {\tt yacc} makes it easy to change
a language. As an illustration, let's add unary minus to {\tt hoc1},
so that expressions like {\tt-3-4} are evaluated, not rejected
as syntax errors.

Exactly two lines have to be added to {\tt hoc.y}. A new token
{\tt UNARYMINUS} is added to the end of the precedence section,
to make unary minus have highest precedence:
\begincode
%left  '+' '-'
%left  '*' '/'
%left  UNARYMINUS      /* new */
\endcode
\noindent
The grammar is augmented with one more production for {\tt expr}:
\begincode
expr:    NUMBER                      { $$ = $1; }
~      | '-' expr  %prec UNARYMINUS  { $$ = -$2; }  /* new */
\endcode
\noindent
The {\tt\%prec} says that a unary minus sign (that is, a minus
sign before an expression) has the precedence of {\tt UNARYMINUS}
(high); the action is to change the sign. A minus sign between
two expressions takes the default precedence.

\exercise 8-2.
Add the operators {\tt\%} (modulus or remainder) and unary {\tt+}
to {\tt hoc1}. Suggestion: look at {\tt frexp}(3) [or rather
{\tt fmod}(3)].\endexercise

\subsect A digression on {\tt make}.
It's a nuisance to have to type two commands to compile a new
version of {\tt hoc1}. Although it's certainly easy to make a
shell file that does the job, there's a better way, one that
will generalize nicely later on when there is more than one
source file in the program. The program {\tt make} reads a
specification of how the components of a program depend on
each other, and how to process them to create an up-to-date
version of the program. It checks the times at which the
various components were last modified, figures out the
minimum amount of recompilation that has to be done to make
a consistent new version, then runs the processes. {\tt make}
also understands the intricacies of multi-step processes like
{\tt yacc}, so these tasks can be put into a {\tt make}
specification without spelling out the individual steps.

{\tt make} is most useful when the program being created
is large enough to be spread over several source files,
but it's handy even for something as small as {\tt hoc1}.
Here is the {\tt make} specification for {\tt hoc1}, which
{\tt make} expects in a file called {\tt Makefile} or
{\tt makefile}.
\begincode
hoc1: hoc.o
~       $(CC) $(CFLAGS) hoc.o -o hoc1
\endcode
\noindent
The second line is indented with a tab, not with blanks!
This makefile says that {\tt hoc1} depends on {\tt hoc.o}, and
that {\tt hoc.o} is converted into {\tt hoc1} by running the
C~compiler and putting the output in {\tt hoc1}.
{\tt make} already knows how to convert the {\tt yacc} source
file in {\tt hoc.y} to an object file {\tt hoc.o}:
\begincode
$ make                 \it Make the first thing in\tt Makefile\it,\tt hoc1
yacc hoc.y
cc -c y.tab.c
rm y.tab.c
mv y.tab.o hoc.o
cc hoc.o -o hoc1
$ make                 \it Do it again\tt
`hoc1' is up to date.   make\it realizes it's unnecessary\tt
$
\endcode


\section Stage 2: Variables and error recovery

The next step (a small one) is to add ``memory'' to {\tt hoc1},
to make {\tt hoc2}. The memory has 26 variables, named {\tt a}
to {\tt z}. This isn't very elegant, but it's an easy and useful
intermediate step. We'll also add some error handling. If you
try {\tt hoc1}, you'll recognize that its approach to syntax
errors is to print a message and die, and its treatment of
arithmetic errors like division by zero is reprehensible:

\begincode
$ hoc1
1/0
Floating exception - core dumped
$
\endcode

The changes needed for these new features are modest, about
35~lines of code. The lexical analyzer {\tt yylex} has to
recognize letters as variables; the grammar has to include
productions of the form
\begincode
expr:   VAR
~     | VAR '=' expr
\endcode
\noindent
An expression can contain an assignment, which permits multiple
assignments like
\begincode
x = y = z = 0
\endcode

The easiest way to store the values of the variables is in a
26-element array; the single-letter variable name can be used
to index the array. But if the grammar is to process both
variable names and values in the same stack, {\tt yacc} has
to be told that its stack contains a union of a {\tt double}
and an {\tt int}, not just a {\tt double}. This is done with
the {\tt\%union} declaration near the top. A {\tt\#define}
or a {\tt typedef} is fine for setting the stack to a basic
type like {\tt double}, but the {\tt\%union} mechanism is
required for union types because {\tt yacc} checks for
consistency in expressions like {\tt\$\$=\$2}.

Here is the grammar part of {\tt hoc.y} for {\tt hoc2}:
\begincode
%{
double mem[26];          /* memory for variables 'a' to 'z' */
%}
%union {
~       double  val;     /* actual value */
~       int     index;   /* index into mem[] */
}
%token  <val>   NUMBER
%token  <index> VAR      /* VAR is index member of union */
%type   <val>   expr     /* expr is val member of union */
%right  '='
%left   '+' '-'
%left   '*' '/'
%left   UNARYPM
%%
list:     /* nothing */
~       | list '\\n'
~       | list expr '\\n'      { printf("\\t%.8g\\n", $2); }
~       | list error '\\n'     { yyerrok; }
~       ;
expr:     NUMBER
~       | VAR            { $$ = mem[$1]; }
~       | VAR '=' expr   { $$ = mem[$1] = $3; }
~       | expr '+' expr  { $$ = $1 + $3; }
~       | expr '-' expr  { $$ = $1 - $3; }
~       | expr '*' expr  { $$ = $1 * $3; }
~       | expr '/' expr  { if ($3 == 0.0)
~                            execerror("division by zero", "");
~                          $$ = $1 / $3; }
~       | '(' expr ')'   { $$ = $2; }
~       | '-' expr  %prec UNARYPM  { $$ = -$2; }
~       ;
%%
~       /* end of grammar */
...
\endcode

\noindent
The {\tt\%union} says that stack elements hold either a
{\tt double} (a number, the usual case), or an {\tt int},
which is an index into the array {\tt mem}. The {\tt\%token}
declarations have been augmented with a type indicator.
The {\tt\%type} declaration specifies that {\tt expr} is the
{\tt<val>} member of the union, i.e., a {\tt double}.
The type information makes it possible for {\tt yacc}
to generate references to the corect members of the union.
Notice also that {\tt=} is right-associative, while the
other operators are left-associative.

Error handling comes in several pieces. The obvious one is
a test for a zero divisor; if one occurs, an error routine
{\tt execerror} is called.

A second test is to catch the ``floating point exception''
signal that occurs when a floating point number overflows.
The signal is set in {\tt main}.

The final part of error recovery is the addition of a
production for {\tt error}. ``{\tt error}'' is a reserved
word in a {\tt yacc} grammar; it provides a way to anticipate
and recover from a syntax error. If an error occurs, {\tt yacc}
will eventually try to use this production, recognize the
error as grammatically ``correct,'' and thus recover.
The action {\tt yyerrok} sets a flag in the parser that
permits it to get back into a sensible parsing state.
Error recovery is difficult in any parser; you should be aware
that we have taken only the most elementary steps here, and
have skipped rapidly over {\tt yacc}'s capabilities as well.

The actions in the {\tt hoc2} grammar are not much changed.
Here is {\tt main}, to which we have added {\tt setjmp} to
save a clean state suitable for resuming after an error.
{\tt execerror} does the matching {\tt longjmp}.
\begincode
...
#include <signal.h>
#include <setjmp.h>
jmp_buf begin;
\medskip
int main(int argc, char *argv[])  /* hoc2 */
{
~       void fpecatch(int);
\medskip
~       progname = argv[0];
~       setjmp(begin);
~       signal(SIGFPE, fpecatch);
~       yyparse();
~       return 0;
}
\medskip
void execerror(char *s, char *t)  /* run-time error recovery */
{
~       warning(s, t);
~       longjmp(begin, 0);
}
\medskip
void fpecatch(int signum)  /* catch floating point exceptions */
{
~       execerror("floating point exception", (char *) 0);
}
\endcode
\noindent
For debugging, we found it convenient to have {\tt execerror} call
{\tt abort}(3), which causes a core dump that can be perused with
{\tt adb} or {\tt sdb} [or {\tt gdb}]. Once the program
is fairly robust, {\tt abort} is replaced by {\tt longjmp}.

The lexical analyzer is a little different in {\tt hoc2}.
There is an extra test for a lower-case letter, and since
{\tt yylval} is now a union, the proper member has to be set
before {\tt yylex} returns. Here are the parts that have changed:
\begincode
int yylex(void)  /* hoc2 */
...
~       if (c == '.' || isdigit(c)) {  /* number */
~               ungetc(c, stdin);
~               scanf("%lf", &yylval.val);
~               return NUMBER;
~       }
~       if (islower(c)) {
~               yylval.index = c - 'a';  /* ASCII only */
~               return VAR;
~       }
...
\endcode
\noindent
Again, notice how the token type (e.g., {\tt NUMBER}) is distinct
from its value (e.g., 3.1416);

Let us illustrate variables and error recovery, the new
things in {\tt hoc2}:
\begincode
$ hoc2
x = 355
~       355
y = 113
~       113
p = x/z                         \it z is undefined and thus zero\tt
hoc2: division by zero near line 4     \it Error recovery\tt
x/y
~       3.1415929
1e30 * 1e30                            \it Overflow\tt
hoc2: floating point exception near line 5
...
\endcode
\noindent
Actually, the {\sc PDP}-11 requires special arrangements to detect
floating point overflow, but on most other machines {\tt hoc2}
behaves as shown.

\exercise 8-3.
Add a facility for remembering the most recent value computed,
so that it does not have to be retyped in a sequence of related
computations. One solution is to make it one of the variables,
for instance `{\tt p}' for `previous.'\endexercise

\exercise 8-4.
Modify {\tt hoc} so that a semicolon can be used as an expression
terminator equivalent to a newline.\endexercise


\section Stage 3: Arbitrary variable names; built-in functions

This version, {\tt hoc3}, adds several major new capabilities,
and a corresponding amount of extra code. The main feature is
access to built-in functions:
\begincode
sin   cos   atan   exp   log   log10   sqrt   int   abs
\endcode
\noindent
We have also added an exponentiation operator `{\tt\char"5E}'; it has
the highest precendence, and is right-associative.

Since the lexical analyzer has to cope with built-in names
longer than a single character, it isn't much extra effort
to permit variable names to be arbitrarily long as well.
We will need a more sophisticated symbol table to keep track
of these variables, but once we have it, we can pre-load it
with names and values for some useful constants:
\medskip
\halign{\tabskip1em\indent\tt#\hfil&#\hfil&#\hfil\cr
  DEG&     57.29577951308232087680& $180/\pi$, degrees per radian\cr
  E&      \02.71828182845904523536& $e$, base of natural logarithms\cr
  GAMMA&  \00.57721566490153286060& $\gamma$, Euler-Mascheroni constant\cr
  PHI&    \01.61803398874989484820& $(\sqrt 5+1)/2$, the golden ratio\cr
  PI&     \03.14159265358979323846& $\pi$, circular transcendental number\cr}
\medbreak
\noindent
The result is a useful calculator:
\begincode
$ hoc3
1.5^2.3
~       2.5410306
exp(2.3*log(1.5))
~       2.5410306
sin(PI/2)
~       1
atan(1)*DEG
~       45
...
\endcode

We have also cleaned up the behavior a little. In {\tt hoc2},
the assignment {\tt x=\it expr\/} not only causes the assignment
but also prints the value, because all expressions are printed:
\begincode
$ hoc2
x = 2 * 3.14159
~       6.28318        \it Value printed for assignment to variable\tt
\endcode
\noindent
In {\tt hoc3}, a distinction is made between assignments and
expressions; values are printed only for expressions:
\begincode
$ hoc3
x = 2 * 3.14159        \it Assignment: no value is printed\tt
x                      \it Expression:\tt
~       6.28318        \it\quad value is printed
\endcode

The program that results from all these changes is big enough
(about 250 lines) that it is best split into separate files
for easier editing and faster compilation.
There are now five files instead of one:
\medskip
\halign{\tabskip2em\indent\tt#\hfil&#\hfil\cr
  hoc.y&    Grammar, {\tt main}, {\tt yylex} (as before)\cr
  hoc.h&    Global data structures for inclusion\cr
  symbol.c& Symbol table routines: {\tt lookup}, {\tt install}\cr
  init.c&   Built-ins and constants: {\tt init}\cr
  math.c&   Interfaces to math routines: {\tt Sqrt}, {\tt Log}, etc.\cr}
\medskip
\noindent
This requires that we learn more about how to organize
a multi-file C program, and more about {\tt make} so it can
do some of the work for us.

We'll get back to {\tt make} shortly. First, let us look at
the symbol table code. A symbol has a name, a type (it's
either a {\tt VAR} or a {\tt BLTIN}), and a value. If the
symbol is a {\tt VAR}, the value is a {\tt double}; if the
symbol is a built-in, the value is a pointer to a function
that returns a {\tt double}. This information is needed in
{\tt hoc.y}, {\tt symbol.c}, and {\tt init.c}. We could just
make three copies, but it's too easy to make a mistake or
forget to update one copy when a change is made. Instead
we put the common information into a header file {\tt hoc.h}
that will be included by any file that needs it. (The suffix
{\tt.h} is conventional but not enforced by any program.)
We will also add to the {\tt Makefile} the fact that these
files depend on {\tt hoc.h}, so that when it changes, the
necessary recompilations are done too. Here is {\tt hoc.h}:
\begincode
typedef struct Symbol {  /* symbol table entry */
~       char    *name;
~       short   type;            /* VAR, BLTIN, UNDEF */
~       union {
~               double  val;            /* if VAR */
~               double  (*ptr)();       /* if BLTIN */
~       } u;
~       struct Symbol   *next;   /* to link to another */
} Symbol;
\smallskip
Symbol *install(char *s, int t, double d);
Symbol *lookup(char *s);
\smallskip
void init(void);
void execerror(char *s, char *t);
\endcode
\noindent
The type {\tt UNDEF} is a {\tt VAR} that has not yet been
assigned a value.

The symbols are linked together in a list using the {\tt next}
field in {\tt Symbol}. The list itself is local to {\tt symbol.c};
the only access to it is through the functions {\tt lookup} and
{\tt install}. This makes it easy to change the symbol table
organization if it becomes necessary. (We did that once.)
{\tt lookup} searches the list for a particular name and returns
a pointer to the {\tt Symbol} with that name if found, and zero
otherwise. The symbol table uses linear search, which is entirely
adequate for our interactive calculator, since variables are looked
up only during parsing, not execution. {\tt install} puts a variable
with its associated type and value at the head of the list.
{\tt emalloc} calls {\tt malloc}(3), the standard storage allocator,
and checks the result. These three routines are the contents of
{\tt symbol.c}. The file {\tt y.tab.h} is generated by running
{\tt yacc -d}; it contains {\tt\#define} statements that {\tt yacc}
has generated for tokens like {\tt NUMBER}, {\tt VAR}, {\tt BLTIN},
etc. Here is {\tt symbol.c}:
\begincode
#include "hoc.h"
#include "y.tab.h"
#include <stdlib.h>
#include <string.h>
\medskip
void *emalloc(unsigned nbytes);
\medskip
static Symbol *symlist = 0;  /* symbol table: linked list */
\medskip
Symbol *lookup(char *s)  /* find s in symbol table */
{
~       Symbol *sp;
~       for (sp = symlist; sp; sp = sp->next)
~               if (strcmp(sp->name, s) == 0)
~                       return sp;
~       return 0;  /* not found */
}
\medbreak
Symbol *install(char *s, int t, double d)  /* add s to symtab */
{
~       Symbol *sp = emalloc(sizeof(Symbol));
~       sp->name = emalloc(strlen(s)+1);  /* +1 for '\\0' */
~       strcpy(sp->name, s);
~       sp->type = t;
~       sp->u.val = d;
~       sp->next = symlist;  /* put at front of list */
~       symlist = sp;
~       return sp;
}
\medbreak
void *emalloc(unsigned nbytes)  /* check return from malloc */
{
~       void *p = malloc(nbytes);
~       if (!p) execerror("out of memory", 0);
~       return p;
}
\endcode

The file {\tt init.c} contains definitions for the constants
({\tt PI}, etc.) and function pointers for built-ins; they are
installed in the symbol table by the function {\tt init},
which is called by {\tt main}. Here is {\tt init.c}:
\begincode
#include "hoc.h"
#include "y.tab.h"
#include <math.h>
\medskip
extern double Log(), Log10(), Exp(), Sqrt(), integer();
\medbreak
static struct {        /* Constants */
~   char    *name;
~   double  cval;
} consts[] = {
~   { "PI",    3.14159265358979323846 },
~   { "E",     2.71828182845904523536 },
~   { "GAMMA", 0.57721566490153286060 },  /* Euler */
~   { "DEG",  57.29577951308232087680 },  /* deg/radian */
~   { "PHI",   1.61803398874989484820 },  /* golden ratio */
~   { 0,       0 }
};
\medbreak
static struct {        /* Built-ins */
~   char    *name;
~   double  (*func)();
} builtins[] = {
~   { "sin",    sin     },
~   { "cos",    cos     },
~   { "atan",   atan    },
~   { "log",    Log     },  /* checks argument */
~   { "log10",  Log10   },  /* checks argument */
~   { "exp",    Exp     },  /* checks argument */
~   { "sqrt",   Sqrt    },  /* checks argument */
~   { "int",    integer },
~   { "abs",    fabs    },
~   { 0,        0       }
};
\medbreak
void init(void)  /* install constants and built-ins in symtab */
{
~       int i;
~       Symbol *sp;
\smallbreak
~       for (i = 0; consts[i].name; i++)
~               install(consts[i].name, VAR, consts[i].cval);
~       for (i = 0; builtins[i].name; i++) {
~               sp = install(builtins[i].name, BLTIN, 0.0);
~               sp->u.ptr = builtins[i].func;
~       }
}
\endcode
\noindent
The data is kept in tables rather than being wired into the
code because tables are easier to read and to change. The tables
are declared {\tt static} so that they are visible only within
this file rather than throughout the program. We'll come back
to the math routines like {\tt Log} and {\tt Sqrt} shortly.

With the foundation in place, we can move on to the changes
in the grammar that make use of it. Here is {\tt hoc.y}:
\begincode
%{
#include "hoc.h"
#include <stdio.h>
extern double Pow();
%}
%union {
~       double  val;    /* actual value */
~       Symbol *sym;    /* symbol table pointer */
}
%token  <val>   NUMBER
%token  <sym>   VAR BLTIN UNDEF
%token  <val>   expr asgn
%right  '='
%left   '+' '-'
%left   '*' '/'
%left   UNARYPM
%right  '^'     /* exponentiation */
%%
list:     /* nothing */
~       | list       '\\n'
~       | list asgn  '\\n'
~       | list expr  '\\n'    { printf("\\t%.8g\\n", $2); }
~       | list error '\\n'    { yyerrok; }
~       ;
asgn:     VAR '=' expr  { $$ = $1->u.val = $3; $1->type = VAR; }
~       ;
expr:     NUMBER
~       | VAR { if ($1->type == UNDEF)
~                   execerror("undefined variable", $1->name);
~               $$ = $1->u.val; }
~       | asgn
\goodbreak
~       | BLTIN '(' expr ')'  { $$ = (*($1->u.ptr))($3); }
~       | expr '+' expr  { $$ = $1 + $3; }
~       | expr '-' expr  { $$ = $1 - $3; }
~       | expr '*' expr  { $$ = $1 * $3; }
~       | expr '/' expr  { if ($3 == 0.0)
~                              execerror("division by zero", "");
~                          $$ = $1 / $3; }
\goodbreak
~       | expr '^' expr  { $$ = Pow($1, $3); }
~       | '(' expr ')'   { $$ = $2; }
~       | '-' expr  %prec UNARYPM  { $$ = -$2; }
~       | '+' expr  %prec UNARYPM  { $$ = $2; }
~       ;
%%
~       /* end of grammar */
...
\endcode
\noindent
The grammar now has {\tt asgn}, for assignment, as well as
{\tt expr}; an input line that contains just
\begincode
VAR = expr
\endcode
\noindent
is an assignment, and so no value is printed. Notice, by the way,
how easy it was to add exponentiation to the grammar, including
its right associativity.

The {\tt yacc} stack has a different {\tt\%union}: instead of
referring to a variable by its index in a 26-element table,
there is a pointer to an object of type {\tt Symbol}. The
header file {\tt hoc.h} contains the definition of thi stype.

The lexical analyzer recognizes variable names, looks them up
in the symbol table, an ddecides whether they are variables
({\tt VAR}) or built-ins ({\tt BLTIN}). The type returned by
{\tt yylex} is one of these; both user-defined variables and
pre-defined variables like {\tt PI} are {\tt VAR}'s.

One of the properties of a variable is whether or not it has
been assigned a value, so the use of an undefined variable
can be reported as an error by {\tt yyparse}. The test for
whether a variable is defined has to be in the grammar, not
in the lexical analyzer. When a {\tt VAR} is recognized lexically,
its context isn't yet known; we don't want a complaint that {\tt x}
is undefined when the context is a perfectly legal one such as the
left side of an assignment like {\tt x=1}.

Here is the revised part of {\tt yylex}:
\begincode
int yylex(void)  /* hoc3 */
...
~       if (isalpha(c)) {
~               Symbol *sp;
~               char sbuf[100], *p = sbuf;
~               do {
~                       *p++ = c;
~               } while ((c=getchar()) != EOF && isalnum(c));
~               ungetc(c, stdin);
~               *p = '\\0';
~               if ((sp=lookup(sbuf)) == 0)
~                       sp = install(sbuf, UNDEF, 0.0);
~               yylval.sym = sp;
~               return sp->type == UNDEF ? VAR : sp->type;
~       }
...
\endcode
\noindent
[Required exercise: find the buffer overrun bug and fix it!]

{\tt main} has one extra line, which calls the initialization
routine {\tt init} to install built-ins and pre-defined names
like {\tt PI} in the symbol table. Here it is:
\begincode
#include <setjmp.h>
#include <signal.h>
\medbreak
int main(int argc, char *argv[])  /* hoc3 */
{
~       void fpecatch(int);
\smallskip
~       progname = argv[0];
~       init();
~       setjmp(begin);
~       signal(SIGFPE, fpecatch);
~       yyparse();
~       return 0;
}
\endcode

The only remaining file is {\tt math.c}. Some of the standard
mathematical functions need an error-checking interface for
messages and recovery---for example the standard function
{\tt sqrt} silently returns zero if its argument is negative.
The code in {\tt math.c} uses the error tests found in Section~2
of the {\sl UNIX Programmer's Manual}. This is more reliable
and portable than writing our own tests, since presumably the
specific limitations of the routines are best reflected in the
``official'' code. The header file {\tt<math.h>} contains type
declarations for the standard mathematical functions.
{\tt<errno.h>} contains names for the errors that can be incurred.
Here is {\tt math.c}:
\begincode
#include "hoc.h"
#include <math.h>
#include <errno.h>
\medbreak
double errcheck(double d, char *s);
\medbreak
double Log(double x)   { return errcheck(log(x),   "log");   }
double Log10(double x) { return errcheck(log10(x), "log10"); }
double Exp(double x)   { return errcheck(exp(x),   "exp");   }
double Sqrt(double x)  { return errcheck(sqrt(x),  "sqrt");  }
double Pow(double x, double y) {
~                        return errcheck(pow(x,y), "pow");   }
\smallbreak
double integer(double x) { return (double)(long) x; }
\medbreak
double errcheck(double d, char *s)
{ /* check result of library call */
~       if (errno == EDOM) {
~               errno = 0;
~               execerror(s, "argument out of domain");
~       }
\goodbreak
~       else if (errno == ERANGE) {
~               errno = 0;
~               execerror(s, "result out of range");
~       }
~       return d;
}
\endcode

An interesting (and ungrammatical) diagnostic appears when
we run {\tt yacc} on the new grammar:
\begincode
$ yacc hoc.y
conflicts: 1 shift/reduce
$
\endcode
\noindent
The ``shift/reduce'' message means that the {\tt hoc3} grammar
is ambiguous: the single line of input {\tt x\kern.5ex=\kern.5ex 1}
can be parsed in two ways:
\medskip
\centerline{\epsfbox{unixdev-2.mps}\hfil\epsfbox{unixdev-3.mps}}
\medskip
\noindent
The parser can decide that the {\it asgn\/} should be reduced to
an {\it expr\/} and then to a {\it list}, as in the parse tree on
the left, or it can decide to use the following {\tt\\n} immediately
(``shift'') and convert the whole thing to a {\it list\/} without
the intermediate rule, as in the tree on the right. Given the
ambiguity, {\tt yacc} chooses to shift, since this is almost always
the right thing to do with real grammars. You should try to understand
such messages, to be sure that {\tt yacc} has made the right decision.%
\footnote{$\dag$}{\ninepoint The {\tt yacc} message ``reduce/reduce
conflict'' indicates a serious problem, more often the symptom of an
outright error in the grammar than an intentional ambiguity.}
Running {\tt yacc} with the option {\tt-v} produces a voluminous
file called {\tt y.output} that hints at the origin of conflicts.

\exercise 8-5.
As {\tt hoc3} stands, it's legal to say {\tt PI = 3}. Is this a good
idea? How would you change {\tt hoc3} to prohibit assignment to
``constants''?\endexercise

\exercise 8-6.
Add the built-in function {\tt atan2(y,x)}, which returns the angle
whose tangent is {\tt y/x}. Add the built-in {\tt rand()}, which
returns a floating point random variable uniformly distributed on
the interval $(0,1)$. How do you have to change the grammar to allow
for built-ins with different numbers of arguments?\endexercise

\exercise 8-7.
How would you add a facility to execute commands from within {\tt hoc},
similar to the {\tt!}~feature of other {\sc UNIX} programs?\endexercise

\exercise 8-8.
Revise the code in {\tt math.c} to use a table instead of the set
of essentially identical functions that we presented.\endexercise

\subsect Another digression on {\tt make}.
Since the program for {\tt hoc3} now lives on five files, not one,
the {\tt Makefile} is more complicated:
\begincode
YFLAGS = -d                   # force creation of y.tab.h
OBJS = hoc.o init.o math.o symbol.o        # abbreviation
\medskip
hoc3: $(OBJS)
~       $(CC) $(OBJS) -lm -o hoc3
\medskip
hoc.o: hoc.h
\medskip
init.o symbol.o: hoc.h y.tab.h
\medskip
pr:
~       @pr hoc.y hoc.h init.c math.c symbol.c Makefile
\medskip
clean:
~       rm -f $(OBJS) y.tab.[ch]
\endcode
\noindent
The {\tt YFLAGS\kern.5ex=\kern.5ex-d} line adds the option {\tt-d}
to the {\tt yacc} command line generated by {\tt make}; this tells
{\tt yacc} to produce the {\tt y.tab.h} file of {\tt\#define} statements.
The {\tt OBJS\kern.5ex=\kern.5ex\rm...} line defines a shorthand for a
construct to be used several times subsequently. The syntax is not the
same as for shell variables---the parentheses are mandatory. The flag
{\tt -lm} causes the math library to be searched for the mathematical
functions.

{\tt hoc3} now depends on four {\tt.o} files; some of the {\tt.o} files
depend on {\tt.h} files. Given these dependencies, {\tt make} can deduce
what recompilation is needed after changes are made to any of the files
involved. If you want to see what {\tt make} will do without actually
running the processes, try
\begincode
$ make -n
\endcode
\noindent
On the other hand, if you want to force the file times into a consistent
state, the {\tt-t} (``touch'') option will update them without doing
any compilation steps.

Notice that we have added not only a set of dependencies for the
source files but miscellaneous utility routines as well, all neatly
encapsulated in one place. By default, {\tt make} makes the first
thing listed in the {\tt Makefile}, but if you name an item that
labels a dependency rule, like {\tt symbol.o} or {\tt pr}, that
will be made instead. An empty dependency is taken to mean that
the item is never ``up to date,'' so that action will always be done
when requested. Thus
\begincode
$ make pr | lpr
\endcode
\noindent
produces the listing you asked for on a line printer. (The leading
{\tt @} in ``{\tt @pr}'' suppresses the echo of the command being
executed by {\tt make}.) And
\begincode
$ make clean
\endcode
\noindent
removes the {\tt yacc} output files and the {\tt.o} files.

This mechanism of empty dependencies in the {\tt Makefile} is
often preferable to a shell file as a way to keep all the related
computations in a single file. And {\tt make} is not restricted
to program development---it is valuable for packaging any set of
operations that have time dependencies.

\subsect A digression on {\tt lex}.
The program {\tt lex} creates lexical analyzers in a manner analogous
to the way that {\tt yacc} creates parsers: you write a specification
of the lexical rules of your language, using regular expressions and
fragments of C to be executed when a matching string is found.
{\tt lex} translates that into a recognizer. {\tt lex} and {\tt yacc}
cooperate by the same mechanism as the lexical analyzers we have
already written. We are not going into great detail on {\tt lex} here;
the following discussion is mainly to interest you in learning more.
%See the reference manual for {\tt lex} in Volume~2B of the {\sl UNIX
%Programmer's Manual}.

First, here is the {\tt lex} program, from the file {\tt lex.l};
it replaces the function {\tt yylex} that we have used so far.
\begincode
%{
#include "hoc.h"
#include "y.tab.h"
extern int lineno;
%}
%%
[ \\t]   { ; }   /* skip blanks and tabs */
[0-9]+\\.?|[0-9]*\\.[0-9]+ {
~       sscanf(yytext, "%lf", &yylval.val); return NUMBER; }
[a-zA-Z][a-zA-Z0-9]* {
~       Symbol *s;
~       if ((s = lookup(yytext)) == 0)
~               s = install(yytext, UNDEF, 0.0);
~       yylval.sym = s;
~       return s->type == UNDEF ? VAR : s->type; }
\\n      { lineno++; return '\\n'; }
.       { return yytext[0]; }   /* everything else */
\endcode
\noindent
Each ``rule'' is a regular expression like those in {\tt egrep}
or {\tt awk}, except that {\tt lex} recognizes C-style escapes
like {\tt\\t} and {\tt\\n}. The action is enclosed in braces.
The rules are attempted in order, and constructs like {\tt*}
and {\tt+} match as long a string as possible. If the rule matches
the next part of the input, the action is performed. The input
string that matched is accessible in a {\tt lex} string called
{\tt yytext}.

The {\tt Makefile} has to be changed to use {\tt lex}:
\begincode
YFLAGS = -d
OBJS = hoc.o lex.o init.o math.o symbol.o
\medskip
hoc3: $(OBJS)
~       $(CC) $(OBJS) -lm -ll -o hoc3
\medskip
hoc.o: hoc.h
\medskip
lex.o init.o symbol.o: hoc.h y.tab.h
...
\endcode
\noindent
Again, {\tt make} knows how to get from a {\tt.l} file to the
proper {\tt.o}; all it needs from us is the dependency information.
(We also have to add the {\tt lex} library {\tt-ll} to the list
searched by {\tt cc} since the {\tt lex}-generated recognizer
is not self-contained.) The output is spectacular and completely
automatic:
\begincode
$ make
yacc -d hoc.y
conflicts: 1 shift/reduce
cc  -c y.tab.c
rm y.tab.c
mv y.tab.o hoc.o
lex  lex.l
cc  -c lex.yy.c
rm lex.yy.c
mv lex.yy.o lex.o
cc  -c init.c
cc  -c math.c
cc  -c symbol.c
cc hoc.o lex.o init.o math.o symbol.o -lm -ll -o hoc3
$
\endcode

If a signle file is changed, the single command {\tt make} is
enough to make an up-to-date version:
\begincode
$ touch lex.l               \it Change modified-time of \tt lex.l
$ make
lex  lex.l
cc  -c lex.yy.c
rm lex.yy.c
mv lex.yy.o lex.o
cc hoc.o lex.o init.o math.o symbol.o -lm -ll -o hoc3
$
\endcode

We debated for quite a while whether to treat {\tt lex} as a
digression, to be illustrated briefly and then dropped, or as
the primary tool for lexical analysis once the language got
complicated. There are arguments on both sides. The main problem
with {\tt lex} (aside from requiring that the user learn yet
another language) is that it tends to be slow to run and to
produce bigger and slower recognizers than the equivalent C
versions. It is also somewhat harder to adapt its input mechanism
if one is doing anything unusual, such as error recovery or
even input from files. None of these issues is serious in the
context of {\tt hoc}. The main limitation is space: it takes
more pages to describe the {\tt lex} version, so (regretfully)
we will revert to C for subsequent lexical analysis. It is a
good exercise to do the {\tt lex} versions, however.

\exercise 8-9.
Compare the sizes of the two versions of {\tt hoc3}.
Hint: see {\tt size}(1).\endexercise


\section Stage 4: Compmilation into a machine

We are heading towards {\tt hoc5}, an interpreter for a language
with control flow. {\tt hoc4} is an intermediate step, providing
the same functions as {\tt hoc3}, but implemented within the
interpreter framework of {\tt hoc5}. We actually wrote {\tt hoc4}
this way, since it gives us two programs that should behave
identically, which is valuable for debugging. As the input is
parsed, {\tt hoc4} generates code for a simple computer instead
of immediately computing answers. Once the end of a statement is
reached, the generated code is executed (``interpreted'') to
compute the desired result.

The simple computer is a {\it stack machine\/}: when an operand
is encountered, it is pushed onto a stack (more precisely, code
is generated to push it onto a stack); most operators operate on
items on the top of the stack. For example, to handle the assignment
\begincode
x = 2 * y
\endcode
\noindent
the following code is generated:
\begincode
constpush          \it Push a constant onto stack\tt
~ 2                \it\quad... the constant\tt 2
varpush            \it Push symbol table pointer onto stack\tt
~ y                \it\quad... for the variable\tt y
eval               \it Evaluate: replace pointer by value\tt
mul                \it Multiply top two items; product replaces them\tt
varpush            \it Push symbol table pointer onto stack\tt
~ x                \it\quad... for the variable\tt x
assign             \it Store value in variable, pop pointer\tt
pop                \it Clear top value from stack\tt
STOP               \it End of instruction sequence
\endcode
\noindent
When this code is executed, the expression is evaluated and
the result is stored in {\tt x}, as indicated by the comments.
The final {\tt pop} clears the value off the stack because it
is not needed any longer.

Stack machines usually result in simple interpreters, and ours
is no exception: it's just an array containing operators and
operands. The operators are the machine instructions; each is a
function call with its arguments, if any, following the instruction.
Other operands may already be on the stack, as they were in the
example above.

The symbol table code for {\tt hoc4} is identical to that for
{\tt hoc3}; the initialization in {\tt init.c} and the mathematical
functions in {\tt math.c} are the same as well. The grammar is the
same as for {\tt hoc3}, but the actions are quite different.
Basically, each action generates machine instructions and any
arguments that go with them. For example, three items are generated
for a {\tt VAR} in an expression: a {\tt varpush} instruction,
the symbol table pointer for the variable, and an {\tt eval}
instruction that will replace the symbol table pointer by its
value when executed. The code for `{\tt*}' is just {\tt mul},
since the operands for that will already bo on the stack.

\begincode
%{
#include "hoc.h"
#define code2(c1,c2)    code(c1); code(c2)
#define code3(c1,c2,c3) code(c1); code(c2); code(c3)
%}
\smallbreak
%union{
~       Symbol  *sym;   /* symbol table pointer */
~       Inst    *inst;  /* machine instruction */
}
\smallbreak
%token  <sym>   NUMBER VAR BLTIN UNDEF
%right  '='
%left   '+' '-'
%left   '*' '-'
%left   UNARYPM
%right  '^'     /* exponentiation */
\smallbreak
%%
list:     /* nothing */
~       | list       '\\n'
~       | list asgn  '\\n'  { code2(drop, STOP); return 1; }
~       | list expr  '\\n'  { code2(print, STOP); return 1; }
~       | list error '\\n'  { yyerrok; }
~       ;
\smallbreak
asgn:     VAR '=' expr   { code3(varpush, (Inst)$1, assign); }
~       ;
\smallbreak
expr:     NUMBER         { code2(constpush, (Inst)$1); }
~       | VAR            { code3(varpush, (Inst)$1, eval); }
~       | asgn
~       | BLTIN '(' expr ')' { code2(bltin, (void*)$1->u.ptr); }
~       | expr '+' expr  { code(add); }
~       | expr '-' expr  { code(sub); }
~       | expr '*' expr  { code(mul); }
~       | expr '/' expr  { code(div); }
~       | expr '^' expr  { code(power); }
~       | '(' expr ')'
~       | '-' expr  %prec UNARYPM  { code(negate); }
~       | '+' expr  %prec UNARYPM
~       ;
%%
~       /* end of grammar */
...
\endcode
\noindent
{\tt Inst} is the data type of a machine instruction (a pointer to
a function returning an {\tt int}), which we will return to shortly.
Notice that the arguments to {\tt code} are function names, that is,
pointers to functions, or other values that are coerced to function
pointers.

We have changed {\tt main} somewhat. The parser now returns after
each statement or expression; the code that it generated is executed.
{\tt yyparse} returns zero at end of file.
\begincode
#include <ctype.h>
#include <setjmp.h>
#include <signal.h>
#include <stdio.h>
\medbreak
int main(int argc, char *argv[])  /* hoc4 */
{
~       void fpecatch(int);
\smallskip
~       progname = argv[0];
~       init();
~       setjmp(begin);
~       signal(SIGFPE, fpecatch);
\smallskip
~       for (initcode(); yyparse(); initcode())
~               execute(prog);
\smallskip
~       return 0;
}
\endcode

The lexical analyzer is only a little different. The main change
is that numbers have to be preserved, not used immediately. The
easiest way to do this is to install them in the symbol table
along with the variables. Here is the changed part of {\tt yylex}:
\begincode
int yylex(void)  /* hoc4 */
...
~       if (c == '.' || isdigit(c)) {  /* number */
~               double d;
~               ungetc(c, stdin);
~               scanf("%lf", &d);
~               yylval.sym = install("", NUMBER, d);
~               return NUMBER;
~       }
...
\endcode

Each element on the interpreter stack is either a floating point
value or a pointer to a symbol table entry; the stack data type
is a union of these. The machine itself is an array of pointers
that point either to routines like {\tt mul} that perform an
operation, or to data in the symbol table.
The header file {\tt hoc.h} has to be augmented to include these
data structures and function declarations for the interpreter,
so they will be known where necessary throughout the program.
(By the way, we chose to put all this information in one file
instead of two. In a larger program, it might be better to divide
the header information into several files so that each is included
only where really needed.) Here is {\tt hoc.h}:

\begincode
typedef struct Symbol {  /* symbol table entry */
~       char   *name;
~       short   type;    /* VAR, BLTIN, UNDEF */
~       union {
~               double  val;         /* if VAR */
~               double  (*ptr)();    /* if BLTIN */
~       } u;
~       struct Symbol   *next;  /* to link to another */
} Symbol;
\medbreak
Symbol *install(char *s, int t, double d);
Symbol *lookup(char *s);
\medbreak
void init(void);
void execerror(char *s, char *t);
\medbreak
typedef union Datum {    /* interpreter stack type */
~       double  val;     /* for literal numbers */
~       Symbol *sym;     /* for variables */
} Datum;
\medbreak
typedef void (*Inst)();  /* machine instruction */
#define STOP (Inst) 0
\medbreak
extern  Inst prog[];
extern  void constpush(), varpush(), drop();
extern  void add(), sub(), mul(), divide(), power(), negate();
extern  void eval(), assign(), bltin(), print();
\medbreak
extern  void initcode(void);
extern  Inst *code(Inst f);
extern  void execute(Inst *p);
\endcode

\noindent
[Renamed {\tt div} to {\tt divide} to avoid collision
with {\tt div}(3) from the standard library.]

The routines that execute the machine instructions and
manipulate the stack are kept in a new file called {\tt code.c}.
Since it is about 150 lines long, we will show it in pieces.

\begincode
#include "hoc.h"
#include "y.tab.h"
#include <stdio.h>
\medbreak
#define NSTACK  256
static  Datum   stack[NSTACK];  /* the stack */
static  Datum  *stackp;         /* next free spot on stack */
\medbreak
#define NPROG   2000
static  Inst    prog[NPROG];    /* the machine */
static  Inst   *progp;          /* next free spot (code gen) */
static  Inst   *pc;             /* program counter (runtime) */
\medbreak
void initcode(void)  /* initialize for code generation */
{
~       stackp = stack;
~       progp = prog;
}
\endcode
\noindent
The stack is manipulated by calls to {\tt push} and {\tt pop}:
\begincode
static void push(Datum d)  /* push d onto stack */
{
~       if (stackp >= &stack[NSTACK])
~               execerror("stack overflow", 0);
~       *stackp++ = d;
}
\medskip
static Datum pop(void)  /* pop and return top from stack */
{
~       if (stackp <= stack)
~               execerror("stack underflow", 0);
~       return *--stackp;
}
\endcode

The machine is generated during parsing by calls to the function
{\tt code}, which simply puts an instruction into the next free
spot in the array {\tt prog}. It returns the location of the
instruction (which is not used in {\tt hoc4}).
\begincode
Inst *code(Inst f)  /* install one instruction or operand */
{
~       Inst *oprogp = progp;
~       if (progp >= &prog[NPROG])
~               execerror("program too big", 0);
~       *progp++ = f;
~       return oprogp;
}
\endcode

Execution of the machine is simple; in fact, it's rather neat how
small the routine is that ``runs'' the machine once it's set up:
\begincode
void execute(Inst *p)  /* run the machine */
{
~       for (pc = p; *pc != STOP; )
~               (*(*pc++))();
}
\endcode
\noindent
Each cycle executes the function pointed to by the instruction
pointed to by the program counter {\tt pc}, and increments {\tt pc}
so it's ready for the next instruction. An instruction with opcode
{\tt STOP} terminates the loop. Some instructions, such as
{\tt constpush} and {\tt varpush}, also increment {\tt pc} to step
over any arguments that follow the instruction.
\begincode
void constpush(void)  /* push constant onto stack */
{
~       Datum d;
~       d.val = ((Symbol *) *pc++)->u.val;
~       push(d);
}
\medbreak
void varpush(void)  /* push variable onto stack */
{
~       Datum d;
~       d.sym = (Symbol *) (*pc++);
~       push(d);
}
\medbreak
void drop(void)  /* pop and discard top item from stack */
{
~       (void) pop();
}
\endcode
\noindent
[{\tt drop} is the instruction form of {\tt pop}; in the book,
{\tt pop} is used as an instruction, but this fails with
recent C~compilers because it has a different signature.]

The rest of the machine is easy. For instance, the arithmetic
operations are all basically the same, and were created by
editing a single prototype. Here is {\tt add}:

\begincode
void add(void)  /* add top two elems on stack */
{
~       Datum d2 = pop();
~       Datum d1 = pop();
~       d1.val += d2.val;
~       push(d1);
}
\endcode

\noindent
The remaining routines are equally simple.
\begincode
void eval(void)  /* evaluate variable on stack */
{
~       Datum d = pop();
~       if (d.sym->type == UNDEF)
~               execerror("undefined variable", d.sym->name);
~       d.val = d.sym->u.val;
~       push(d);
}
\medbreak
void assign(void)  /* assign to top var next value */
{
~       Datum d1 = pop();
~       Datum d2 = pop();
~       if (d1.sym->type != VAR && d1.sym->type != UNDEF)
~               execerror("assignment to non-variable",
~                         d1.sym->name);
~       d1.sym->u.val = d2.val;
~       d1.sym->type = VAR;
~       push(d2);  /* push back value because asgn is an expr */
}
\medbreak
void print(void)  /* pop top value from stack, print it */
{
~       Datum d = pop();
~       printf("\\t%.8g\\n", d.val);
}
\medbreak
void bltin(void)  /* evaluate built-in on top of stack */
{
~       Datum d = pop();
~       d.val = (*(double (*)())(void*)(*pc++))(d.val);
~       push(d);
}
\endcode

\noindent
The hardest part is the cast in {\tt bltin}, which says that
{\tt*pc} should be cast to ``pointer to function returning a
{\tt double},'' and that function executed with {\tt d.val}
as argument. [The intermediate {\tt(void*)} cast silences
a compiler warning because an {\tt Inst} returns {\tt int},
not {\tt double}.]

The diagnostics in {\tt eval} and {\tt assign} should never
occur if everything is working properly; we left them in in
case some program error causes the stack to be curdled.
The overhead in time and space is small compared to the benefit
of detecting the error if we make a careless change in the
program. (We did, several times).

C's ability to manipulate pointers to functions leads to
compact and efficient code. An alternative, to make the
operators constants and combine the semantic functions into
a big {\tt switch} statement in {\tt execute}, is straightforward
and is left as an exercise.

\subsect A third digression on {\tt make}.
As the source code for {\tt hoc} grows, it becomes more and
more valuable to keep track mechanically of what has changed
and what depends on that. The beauty of {\tt make} is that
it automates jobs that we would otherwise do by hand (and get
wrong sometimes) or by creating a specialized shell file.

We have made two improvements to the {\tt Makefile}. The first
is based on the observation that although several files depend
on the {\tt yacc}-defined constants in {\tt y.tab.h}, there's
no need to recompile them unless the constants change---changes
to the C~code in {\tt hoc.y} don't affect anything else.
In the new {\tt Makefile} the {\tt.o} files depend on a new
file {\tt x.tab.h} that is updated only when the {\it contents\/}
of {\tt y.tab.h} change. The second improvement is to make the
rule for {\tt pr} (printing the source files) depend on the source
files, so that only changed files are printed.

The first of these changes is a great time-saver for larger
programs when the grammar is static but the semantics are not
(the usual situation). The second change is a great paper-saver.

Here is the new {\tt Makefile} for {\tt hoc4}:
\begincode
YFLAGS = -d
OBJS = hoc.o code.o init.o math.o symbol.o
\medskip
hoc4: $(OBJS)
~       $(CC) $(OBJS) -o hoc4 -lm
\medskip
hoc.o code.o init.o symbol.o: hoc.h
code.o init.o symbol.o: x.tab.h
\medskip
x.tab.h: y.tab.h
~       -cmp -s x.tab.h y.tab.h || cp y.tab.h x.tab.h
\medskip
pr: hoc.y hoc.h code.c init.c math.c symbol.c
~       @pr $?
~       @touch pr
\medskip
clean:
~       rm -f $(OBJS) [xy].tab.[ch]
\endcode

\noindent
The `{\tt-}' before {\tt cmp} tells {\tt make} to carry on even
if the {\tt cmp} fails; this permits the process to work even
if {\tt x.tab.h} doesn't exist. (The {\tt-s} option causes
{\tt cmp} to produce no output but set the exit status.)
The symbol {\tt\$?} expands into the list of items from the
rule that are not up to date. Regrettably, {\tt make}'s
notational conventions are at best loosely related to those
of the shell.

To illustrate how these operate, suppose that everything is
up to date. Then:
\begincode
$ touch hoc.y                 \it Change date of\tt hoc.y
\smallbreak
$ make
yacc -d hoc.y
conflicts: 1 shift/reduce
cc  -c y.tab.c
rm y.tab.c
mv y.tab.o hoc.o
cmp -s x.tab.h y.tab.h || cp y.tab.h x.tab.h
cc hoc.o code.o init.o math.o symbol.o -o hoc4 -lm
\smallbreak
$ make -n pr                  \it Print changed files\tt
pr hoc.y
touch pr
$
\endcode
\noindent
Notice that nothing was recompiled except {\tt hoc.y}, because
the {\tt y.tab.h} file was the same as the previous one.

\exercise 8-10.
Make the sizes of {\tt stack} and {\tt prog} dynamic, so that
{\tt hoc4} never runs out of space if memory can be obtained
by calling {\tt malloc}.\endexercise

\exercise 8-11.
Modify {\tt hoc4} to use a {\tt switch} on the type of operation
in {\tt execute} instead of calling functions. How do the versions
compare in lines of source code and execution spead? How are they
likely to compare in case of maintenance and growth?\endexercise


\section Stage 5: Control flow and relational operators

This version, {\tt hoc5}, derives the benefit of the effort
we put into making an interpreter. It provides {\tt if-else}
and {\tt while} statements like those in~C, statement grouping
with {\tt\ocb} and {\tt\ccb}, and a {\tt print} statement.
A full set of relational operators is included ({\tt>}, {\tt>=},
etc.), as are the {\sc AND} and {\sc OR} operators {\tt\&\&}
and {\tt||}. (These last two do not guarantee the left-to-right
evaluation that is such an asset in~C; they evaluate both conditions
even if it is not necessary.)

The grammar has been augmented with tokens, non-terminals, and
productions for {\tt if}, {\tt while}, braces, and the relational
operators. This makes it quite a bit longer, but (except possibly
for the {\tt if} and {\tt while}) not much more complicated:

\begincode
%{
#include "hoc.h"
#define code2(c1,c2)    code(c1); code(c2)
#define code3(c1,c2,c3) code(c1); code(c2); code(c3)
%}
%union {
~       Symbol  *sym;   /* symbol table pointer */
~       Inst    *inst;  /* machine instruction */
}
\smallbreak
%token  <sym>   NUMBER PRINT VAR BLTIN UNDEF WHILE IF ELSE
%type   <inst>  stmt asgn expr stmtlist cond while if end
%right  '='
%left   OR
%left   AND
%left   GT GE LT LE EQ NE
%left   '+' '-'
%left   '*' '/'
%left   UNARYPM NOT
%right  '^'
\smallbreak
%%
list:     /* nothing */
~       | list       '\\n'
~       | list asgn  '\\n'  { code2(pop, STOP);   return 1; }
~       | list stmt  '\\n'  { code(STOP);         return 1; }
~       | list expr  '\\n'  { code2(print, STOP); return 1; }
~       | list error '\\n'  { yyerrok; }
~       ;
\smallbreak
asgn:     VAR '=' expr  {$$=$3; code3(varpush,(Inst)$1,assign);\rlap}
~       ;
\smallbreak
stmt:     expr          { code(drop); }
~       | PRINT expr    { code(prexpr); $$ = $2; }
~       | while cond stmt end {
~               ($1)[1] = (Inst)$3;    /* body of loop */
~               ($1)[2] = (Inst)$4; }  /* end, if cond fails */
~       | if cond stmt end {           /* else-less if */
~               ($1)[1] = (Inst)$3;    /* thenpart */
~               ($1)[3] = (Inst)$4; }  /* end, if cond fails */
~       | if cond stmt end ELSE stmt end { /* if with else */
~               ($1)[1] = (Inst)$3;    /* thenpart */
~               ($1)[2] = (Inst)$6;    /* elsepart */
~               ($1)[3] = (Inst)$7; }  /* end, if cond fails */
~       | '{' stmtlist '}'    { $$ = $2; }
~       ;
\goodbreak
cond:     '(' expr ')'  { code(STOP); $$ = $2; }
~       ;
\goodbreak
while:    WHILE  { $$ = code3(whilecode, STOP, STOP); }
~       ;
\goodbreak
if:       IF     { $$ = code(ifcode); code3(STOP, STOP, STOP); }
~       ;
\goodbreak
end:      /* nothing */     { code(STOP); $$ = progp; }
~       ;
\goodbreak
stmtlist: /* nothing */     { $$ = progp; }
~       | stmtlist '\\n'
~       | stmtlist stmt
~       ;
\goodbreak
expr:     NUMBER    { $$ = code2(constpush, (Inst)$1); }
~       | VAR       { $$ = code3(varpush, (Inst)$1, eval); }
~       | asgn
~       | BLTIN '(' expr ')'
~                   { $$ = $3; code2(bltin, (void*)$1->u.ptr); }
~       | '(' expr ')'   { $$ = $2; }
\goodbreak
~       | expr '+' expr  { code(add); }
~       | expr '-' expr  { code(sub); }
~       | expr '*' expr  { code(mul); }
~       | expr '/' expr  { code(divide); }
~       | expr '^' expr  { code(power); }
\goodbreak
~       | '-' expr %prec UNARYPM { $$=$2; code(negate); }
~       | '+' expr %prec UNARYPM { $$=$2; }
\goodbreak
~       | expr GT expr   { code(gt); }
~       | expr GE expr   { code(ge); }
~       | expr LT expr   { code(lt); }
~       | expr LE expr   { code(le); }
~       | expr EQ expr   { code(eq); }
~       | expr NE expr   { code(ne); }
~       | expr AND expr  { code(land); }
~       | expr OR expr   { code(lor); }
~       | NOT expr       { $$ = $2; code(lnot); }
~       ;
%%
\endcode

\noindent
The grammar has five shift/reduce conflicts, all like the one
mentioned in {\tt hoc3}.

Notice that {\tt STOP} instructions are now generated in several
places to terminate a sequence; as before, {\tt progp} is the
locatoin of th enext instruction that will be generated. When
executed those {\tt STOP} instructions will terminate the loop
in {\tt execute}. The production for {\tt end} is in effect a
subroutine, called from several places, that generates a {\tt STOP}
and returns the location of the instruction that follows it.

The code generated for {\tt while} and {\tt if} needs particular
study. When the keyword {\tt while} is encountered, the operation
{\tt whilecode} is generated, and its position in the machine
is returned as the value of the production
\begincode
while:  WHILE
\endcode
\noindent
At the same time, however, the two following positions in the
machine are also reserved, to be filled in later. The next
code generated is the expression that makes up the condition
part of the {\tt while}. The value returned by {\tt cond} is
the beginning of the code for the condition. After the whole
{\tt while} statement has been recognized, the two extra
positions reserved after the {\tt whilecode} instruction are
filled with the locations of the loop body and the statement
that follows the loop. (Code for that statement will be generated
next.)
\begincode
~   | while cond stmt end {
~           ($1)[1] = (Inst)$3;    \it body of loop\tt
~           ($1)[2] = (Inst)$4; }  \it end, if cond fails\tt
\endcode
\noindent
{\tt\$1} is the location in the machine at which {\tt whilecode}
is stored; therefore, {\tt(\$1)[1]} and {\tt(\$1)[2]} are the
next two positions.

The situation for an {\tt if} is similar, except that three
spots are reserved, for the {\tt then} and {\tt else} parts
and the statement that follows the {\tt if}. We will return
shortly to how this operates.

\nobreak\medskip
\centerline{\epsfbox{unixdev-4.mps}}
\medbreak

Lexical analysis is somewhat longer this time, mainly to
pick up the additional operators:

\begincode
int yylex(void)  /* hoc5 */
...
~       switch (c) {
~       case '>':   return follow('=', GE, GT);
~       case '<':   return follow('=', LE, LT);
~       case '=':   return follow('=', EQ, '=');
~       case '!':   return follow('=', NE, NOT);
~       case '|':   return follow('|', OR, '|');
~       case '&':   return follow('&', AND, '&');
~       case '\\n':  lineno++; return '\\n';
~       default:    return c;
~       }
}
\endcode

\noindent
{\tt follow} looks ahead one character, and puts it back
on the input with {\tt ungetc} if it was not what was
expected.
\begincode
int follow(int expect, int ifyes, int ifno)  /* look ahead */
{
~       int c = getchar();
~       if (c == expect)  return ifyes;
~       ungetc(c, stdin); return ifno;
}
\endcode

There are more function declarations in {\tt hoc.h}---all of
the relationals, for instance---but it's otherwise the same
idea as in {\tt hoc4}. Here are the last few lines:

\begincode
...
typedef void (*Inst)();  /* machine instruction */
#define STOP (Inst) 0
\medbreak
extern  Inst prog[];
extern  void constpush(), varpush(), drop();
extern  void add(), sub(), mul(), divide(), power(), negate();
extern  void eval(), assign(), bltin(), print();
extern  void prexpr(), ifcode(), whilecode();
extern  void eq(), ne(), gt(), ge(), lt(), le();
extern  void land(), lor(), lnot();  /* logical and/or/not */
\endcode

\noindent
Most of {\tt code.c} is the same too, although there are a lot
of obvious new routines to handle the relational operators.
The function {\tt le} (``less than or equal to'') is a typical
example:
\begincode
void le(void)
{
~       Datum d2 = pop();
~       Datum d1 = pop();
~       d1.val = (double) (d1.val <= d2.val);
~       push(d1);
}
\endcode

The two routines that are not obvious are {\tt whilecode} and
{\tt ifcode}. The critical point for understanding them is to
realize that {\tt execute} marches along a sequence of
instructions until it finds a {\tt STOP}, whereupon it returns.
Code generation during parsing has carefully arranged that a
{\tt STOP} terminates each sequence of instructions that should
be handled by a single call of {\tt execute}. The body of a
{\tt while}, and the condition, {\tt then} and {\tt else} parts
of an {\tt if} are all handled by recursive calls to {\tt execute}
that return to the parent level when they have finished their task.
The control of these recursive tasks is done by code in
{\tt whilecode} and {\tt ifcode} that corresponds directly
to {\tt while} and {\tt if} statements.

\begincode
void whilecode(void)
{
~       Datum d;
~       Inst *savepc = pc;     /* loop body */
\smallbreak
~       execute(savepc+2);     /* condition */
~       d = pop();
~       while (d.val) {
~               execute(*((Inst **)(savepc)));  /* body */
~               execute(savepc+2);
~               d = pop();
~       }
~       pc = *((Inst **)(savepc+1));  /* next statement */
}
\endcode

\noindent
Recall from our discussion earlier that the {\tt whilecode} operation
is followed by a pointer to the body of the loop, a pointer to the
next statement, and then the beginning of the condition part.
When {\tt whilecode} is called, {\tt pc} has already been incremented,
so it points to the loop body pointer. Thus {\tt pc+1} points to the
following statement, and {\tt pc+2} points to the condition.
[Indeed {\tt pc} points to a pointer to the body code and thus
is dereferenced before being passed to {\tt execute}; similarly, the
pointer at {\tt pc+1} is dereferenced before being assigned to {\tt pc}.]

{\tt ifcode} is very similar; in this case, upon entry {\tt pc}
points to then {\tt then} part, {\tt pc+1} to the {\tt else},
{\tt pc+2} to the next statement, and {\tt pc+3} is the condition.

\begincode
void ifcode(void)
{
~       Datum d;
~       Inst *savepc = pc;     /* then part */
\smallbreak
~       execute(savepc+3);     /* condition */
~       d = pop();
~       if (d.val)
~               execute(*((Inst **)(savepc)));
~       else if (*((Inst **)(savepc+1)))  /* else part? */
~               execute(*((Inst **)(savepc+1)));
~       pc = *((Inst **)(savepc+2));      /* next stmt */
}
\endcode

The initialization code in {\tt init.c} is augmented a little as well,
with a table of keywords that are stored in the symbol table along
with everything else:

\begincode
...
static struct {  /* Keywords */
~       char *name;
~       int   kval;
} keywords[] = {
~       "if",      IF,
~       "else",    ELSE,
~       "while",   WHILE,
~       "print",   PRINT,
~       0,         0
};
...
\endcode

\noindent
We also need one more loop in {\tt init}, to install keywords.
\begincode
~  for (i = 0; keywords[i].name; i++)
~          install(keywords[i].name, keywords[i].kval, 0.0);
\endcode

No changes are needed in any of the symbol table management;
{\tt code.c} contains the routine {\tt prexpr}, which is called
when a statement of the form {\tt print~\it expr\/} is executed.

\begincode
void prexpr(void)  /* print numeric value */
{
~       Datum d = pop();
~       printf("%.8g\\n", d.val);
}
\endcode

\noindent
This is not the {\tt print} function that is called automatically
to print the final result of an evaluation; that one pops the
stack and adds a tab to the output.

{\tt hoc5} is by now quite a serviceable calculator, although for
serious programming, more facilities are needed. The following
exercises suggest some possibilities.

\exercise 8-12.
Modify {\tt hoc5} to print the machine it generates in a readable
form for debugging.\endexercise

\exercise 8-13.
Add the assignment operators of~C, such as {\tt+=}, {\tt*=}, etc.,
and the increment and decrement operators {\tt++} and {\tt--}.
Modify {\tt\&\&} and {\tt||} so they guarantee left-to-right
evaluation and early termination, as in~C.\endexercise

\exercise 8-14.
Add a {\tt for} statement like that of~C to {\tt hoc5}.
Add {\tt break} and {\tt continue}.\endexercise

\exercise 8-15.
How would you modify the grammar or the lexical analyzer (or both)
of {\tt hoc5} to make it more forgiving about the placement of
newlines? How would you add semicolon as a synonym for newline?
How would you add a comment convention?
What syntax would you use?\endexercise

\exercise 8-16.
Add interrupt handling to {\tt hoc5}, so that a runaway computation
can be stopped without losing the state of variables already
computed.\endexercise

\exercise 8-17.
It is a nuisance to have to create a program in a file, run it,
then edit the file to make a trivial change. How would you modify
{\tt hoc5} to provide an edit command that would cause you to be
placed in an editor with a copy of your {\tt hoc} program already
read in? Hint: consider a {\tt text} opcode.\endexercise

\bye
