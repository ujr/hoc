
\magnification\magstep1
\input fixpdfmag % for pdftex
\input epsf % for including *.mps figures
\input fonts % font size switching

\hsize 15 true cm \advance\hoffset 5 true mm
\vsize 24 true cm \advance\voffset 1 true mm

\parskip=1pt plus 1pt
\parindent=2pc

\font\tfone=cmssbx12 scaled\magstep2
\font\tftwo=cmss12 scaled\magstephalf
\font\headingfont=cmssbx12
\font\sans=cmss10
\font\sc=cmr9 % small caps (relative to cmr10)

\def\section #1\par{\vskip 0pt plus .1\vsize\penalty-250
  \vskip 0pt plus -.1\vsize \vskip 24pt plus 6pt minus 4pt
  \vskip\parskip \leftline{\headingfont #1}%
  \nobreak\medskip\noindent\ignorespaces}

\def\subsect #1.{\bigbreak\noindent{\bf #1.\enspace}\ignorespaces}
\def\exercise #1.{\bigbreak\begingroup\ninepoint
  \noindent{\bf Exercise #1.\enspace}\ignorespaces}
\def\endexercise{\unskip\kern.8ex$\sqcup\mkern-12mu\sqcap$\par\endgroup}

\def\begincode{\medbreak\begingroup\tt
  \obeylines\obeyspaces\frenchspacing\spaceskip=\ttglue
  \catcode`\$=12\catcode`\{=12\catcode`\}=12\catcode`\&=12
  \catcode`\^=12\catcode`\#=12\catcode`\%=12\catcode`\_=12\relax}%
\def\endcode{\medskip\endgroup}

\def\0{\phantom{0}}% to align numbers
\def\\{\char"5C\relax}% backslash in cmtt font
\def\ocb{\char"7B\relax}% opening curly brace in cmtt
\def\ccb{\char"7D\relax}% closing curly brace in cmtt


\topglue 0pc\noindent
Excerpt from {\sl The UNIX Programming Environment}
by Brian W.~Kernighan and Rob Pike,
Prentice-Hall Software Series, 1984.
Copyright 1984 by Bell Telephone Laboratories, Incorporated.
Minimally edited to conform to {\sc ANSI}~C.
\vskip 4pc plus 1pc

\centerline{\tftwo Chapter 8}
\bigskip
\centerline{\tfone PROGRAM DEVELOPMENT}
\medskip
\centerline{\tftwo in the Unix Programming Environment}
\vskip 2pc plus 1pc

\noindent
The {\sc UNIX} system was originally meant as a program development
environment. In this chapter we'll talk about some of the tools that
are particularly suited for developing programs. Our vehicle is a
substantial program, an interpreter for a programming language
comparable in power to {\sc BASIC}. We chose to implement a language
because it's representative of problems encountered in large
programs. Furthermore, many programs can profitably be viewed as
languages that convert a systematic input into a sequence of actions
and outputs, so we want to illustrate the language development tools.

In this chapter, we will cover specific lessons about
\item{--} {\tt yacc}, a parser generator, a program that generates
a parser from a grammatical description of a language;
\item{--} {\tt make}, a program for specifying and controlling the
process by which a complicated program is compiled;
\item{--} {\tt lex}, a program analogous to {\tt yacc}, for making
 lexical analyzers.
\par\noindent
We also want to convey some notions of how to go about such a
project---the importance of starting with something small and letting
it grow; language evolution; and the use of tools.

We will describe the implementation of the language in six stages,
each of which would be useful even if the development went no further.
These stages closely parallel the way that we actually wrote the
program.

\smallskip\item{(1)}
A four-function calculator, providing {\tt + - * /} and parentheses,
that operates on floating point numbers. One expression is typed on
each line; its value is printed immediately.

\smallskip\item{(2)}
Variables with names {\tt a} through {\tt z}. This version also has
unary minus and some defenses against errors.

\smallskip\item{(3)}
Arbitrarily-long variable names, built-in functions for {\tt sin},
{\tt exp}, etc., useful constants like $\pi$ (spelled {\tt PI}
because of typographic limitations), and an exponentiation operator.

\smallskip\item{(4)}
A change in internals: code is generated for each statement and
subsequently interpreted, rather than being evaluated on the fly.
No new features are added, but it leads to~(5).

\smallskip\item{(5)}
Control flow: {\tt if}-{\tt else} and {\tt while}, statement
grouping with {\tt\ocb} and {\tt\ccb}, and relational operators
like {\tt>}, {\tt<=}, etc.

\smallskip\item{(6)}
Recursive functions and procedures, with arguments. We also added
statements for input and for output of strings as well as numbers.

\smallskip\noindent
The resulting language is described in Chapter~9, where it serves
as the main example in our presentation of the {\sc UNIX} document
preparation software. Appendix~2 is the reference manual.

This is a very long chapter, because there's a lot of detail involved
in getting a non-trivial program written correctly, let alone presented.
We are assuming that you understand~C, and that you have a copy of the
{\sl Unix Programmer's Manual,} Volume~2, close at hand, since we
simply don't have space to explain every nuance. Hang in, and be
prepared to read the chapter a couple of times. We have also included
all of the code for the final version in Appendix~3, so you can see
more easily how the pieces fit together.

By the way, we wasted a lot of time debating names for this language
but never came up with anything satisfactory. We settled on {\tt hoc},
which stands for ``high-order calculator.'' The versions are thus
{\tt hoc1}, {\tt hoc2}, etc.


\section Stage 1: A four-function calculator

This section describes the implementation of {\tt hoc1}, a program
that provides about the same capabilities as a minimal pocket
calculator. It has only four
functions: {\tt+}, {\tt-}, {\tt*}, and {\tt/}, but it does have
parentheses that can be nested arbirarily deeply, which few pocket
calculators provide. If you type an expression followed by
{\sc RETURN}, the anwer will be printed on the next line:

\begincode
$ hoc1
4*3*2
~       24
(1+2) * (3+4)
~       21
1/2
~       0.5
355/113
~       3.1415929
-3-4
hoc1: syntax error near line 4\quad\it It doesn't have unary minus yet
\tt$
\endcode

\subsect Grammars.
Ever since Backus-Naur Form was developed for Algol, languages have
been described by formal grammars. The grammar for {\tt hoc1} is small
and simple in its abstract representation:

\medbreak
\indent\indent\vbox{\halign{\tabskip1em\tt#\hfil&\tt#\hfil\cr
 list:& expr \\n\cr
      & list expr \\n\cr
 expr:& NUMBER\cr
      & expr + expr\cr
      & expr - expr\cr
      & expr * expr\cr
      & expr / expr\cr
      & ( expr )\cr}}
\medskip
\noindent
In other words, a {\tt list} is a sequence of expressions, each
followed by a newline. An expression is a number, or a pair of
expressions joined by an operator, or a pharenthesized expression.

This is not complete. Among other things, it does not specify
the normal precedence and associativity of the operators, nor
does it attach a meaning to any construct. And although {\tt list}
is defined in terms of {\tt expr}, and {\tt expr} is defined in
terms of {\tt NUMBER}, {\tt NUMBER} itself is nowhere defined.
These details have to be filled in to go from a sketch of the
language to a working program.

\subsect Overview of yacc.
{\tt yacc} is a {\it parser generator},\footnote{$\dag$}{{\tt yacc}
stands for ``yet another compiler-compiler,'' a comment by its
creator, Steve Johnson, on the number of such programs extant
at the time it was being developed (around 1972). {\tt yacc}
is one of a handful that have flourished.} that is, a program
for converting a grammatical specification of a language like
the one above into a parser that will parse statements in the
language. {\tt yacc} provides a way to associate meanings with
the components of the grammar in such a way that as the parsing
takes place, the meaning can be ``evaluated'' as well. The stages
in using {\tt yacc} are the following.

First, a grammar is written, like the one above, but more precise.
This specifies the syntax of the language. {\tt yacc} can be used
at this stage to warn of errors and ambiguities in the grammar.

Second, each rule or {\it production\/} of the grammar can be
augmented with an {\it action}---a statement of what to do
when an instance of that grammatical form is found in a program
being parsed. The ``what to do'' part is written in~C, with
conventions for connecting the grammar to the C~code.
This defines the semantics of the language.

Third, a {\it lexical scanner\/} is needed, which will read
the input being parsed and break it up into meaningful chunks
for the parser. A {\tt NUMBER} is an example of a lexical
chunk that is several characters long; single-character operators
like {\tt+} and {\tt*} are also chunks. A lexical chunk is called
a {\it token}.

Finally, a controlling routine is needed, to call the parser
that {\tt yacc} built.

{\tt yacc} proceses the grammar and the semantic actions into
a parsing function, named {\tt yyparse}, and writes it out as
a file of C~code. If {\tt yacc} finds no errors, the parser,
the lexical analyzer, and the control routines can be compiled,
perhaps linked with other C~routines, and executed. The operation
of this program is to call repeatedly upon the lexical analyzer
for tokens, recognize the grammatical (syntactic) structure in the
input, and perform the semantic actions as each grammatical rule
is recognized. The entry to the lexical analyzer must be named
{\tt yylex}, since that is the function that {\tt yyparse} calls
each time it wants another token. (All names used by {\tt yacc}
start with~y.)

To be somewhat more precise, the input to {\tt yacc} takes
this form:

\begincode
%{
\it C statements like \tt#include\it, declarations, etc. This section is optional\tt
%}
\begingroup\it yacc declarations: lexical tokens, grammar variables,
\quad precedence and associativity information\endgroup
%%
\begingroup\it grammar rules and actions\endgroup
%%
\begingroup\it more C statements (optional):\endgroup
main() { ...; yyparse(); ... }
yylex() { ... }
...
\endcode

\noindent
This is processed by {\tt yacc} and the result is written into
a file called {\tt y.tab.c}, whose layout is like this:

\smallbreak
\begingroup
\obeylines
{\it C statements from between {\tt\%\ocb} and {\tt\%\ccb}, if any}
{\it C statements from after second {\tt\%\%}, if any:}
{\tt main() \ocb\ ...; yyparse(); ... \ccb}
{\tt yylex() \ocb\ ... \ccb}
...
{\tt yyparse() \ocb\ \it parser, which calls \tt yylex() \ccb}
\endgroup
\smallskip

It is typical of the {\sc UNIX} approach that {\tt yacc} produces
C instead of a compiled object ({\tt.o}) file. This is the most
flexible arrangement---the generated code is portable and amenable
to other processing whenever someone has a good idea.

{\tt yacc} itself is a powerful tool. It takes some effort to learn,
but the effort is repaid many times over. {\tt yacc}-generated parsers
are small, efficient, and correct (though the semantic actions are
your own responsibility); many nasty parsing problems are taken
care of automatically. Language-recognizing programs are easy
to build, and (probably more important) can be modified repeatedly
as the language definition evolves.

\subsect Stage 1 program.
The source code for {\tt hoc1} consists of a grammar with actions,
a lexical routine {\tt yylex}, and a {\tt main}, all in one file
{\tt hoc.y}. ({\tt yacc} filenames traditionally end in {\tt.y},
but this convention is not enforced by {\tt yacc} itself, unlike
{\tt cc} with {\tt.c} files) The grammar part is the first half of
{\tt hoc.y}:

\begincode
%{
#include <stdio.h>      \it includes needed for code later on\tt
#include <ctype.h>
#define YYSTYPE double   /* data type of yacc stack */
%}
\smallbreak
%token  NUMBER
%left   '+' '-'   /* left associative, same precedence */
%left   '*' '/'   /* left associative, higher precedence */
\smallbreak
%%
list:     /* nothing */
~       | list '\\n'
~       | list expr '\\n'  { printf("\\t%.8g\\n", $2); }
~       ;
expr:     NUMBER          { $$ = $1; }
~       | expr '+' expr   { $$ = $1 + $3; }
~       | expr '-' expr   { $$ = $1 - $3; }
~       | expr '*' expr   { $$ = $1 * $3; }
~       | expr '/' expr   { $$ = $1 / $3; }
~       | '(' expr ')'    { $$ = $2; }
~       ;
%%
~       /* end of grammar */
...
\endcode

There's a lot of new information packed into these few lines.
We are not going to explain all of it, and certainly not how
the parser works---for that, you will have to read the {\tt yacc}
manual.

Alternate rules are separated by `{\tt|}'. Any grammar rule can
have an associated action, which will be performed when an instance
of that rule is recognized in the input. An action is a sequence
of C statements enclosed in braces {\tt\ocb} and {\tt\ccb}.
Within an action, {\tt\$\it n\/} (that is, {\tt\$1}, {\tt\$2}, etc.)
refers to the value returned by the $n$th component of the rule,
and {\tt\$\$} is the value to be returned as the value of the
whole rule. So for example, in the rule
\begincode
expr:  NUMBER  { $$ = $1; }
\endcode
\noindent
{\tt\$1} is the value returned by recognizing {\tt NUMBER};
that value is to be returned as the value of the {\tt expr}.
The particular assignment {\tt\$\$=\$1} can be omitted---{\tt\$\$}
is always set to {\tt\$1} unless you explicitly set it to something
else.

At the next level, when the rule is
\begincode
expr:  expr '+' expr  { $$ = $1 + $3; }
\endcode
\noindent
the value of the result {\tt expr} is the sum of the values from
the two component {\tt expr}'s. Notice that {\tt'+'} is {\tt\$2};
every component is numbered.

At the level above this, an expressoin followed by a newline
{\tt'\\n'} is recognized as a list and its value is printed.
If the end of the input follows such a construction, the parsing
process terminates cleanly. A {\tt list} can be an empty string;
this is how blank input lines are handled.

{\tt yacc} input is free form; our format is the recommended standard.

In this implementation, the act of recognizing or parsing the input
also causes immediate evaluation of the expression. In more
complicated situations (including {\tt hoc4} and its successors),
the parsing process generates code for later execution.

You may find it helpful to visualize parsing as drawing a
{\it parse tree\/} like the one in the figure, and to imaginge
values being computed and propagated up the tree from the leaves
towards the root.
\medskip
\centerline{\epsfbox{unixdev-1.mps}}
\centerline{Parse Tree for {\tt 2 + 3 * 4}}
\medskip
\noindent
The values of incompletely-recognized rules are actually kept
on a stack; this is how the values are passed from one rule
to the next. The data type of this stack is normally an {\tt int},
but since we are processing floating point numbers, we have to
override the default. The definition
\begincode
#define YYSTYPE double
\endcode\noindent
sets the stack type to {\tt double}.

Syntactic classes that will be recognized by the lexical analyzer
have to be declared unless they are single character literals like
{\tt+} and~{\tt-}. The declaration {\tt\%token} declares one or
more such objects. Left or right associativity can be specified
if appropriate by using {\tt\%left} or {\tt\%right} instead of
{\tt\%token}. (Left associativity means that {\tt a-b-c} will
be parsed as {\tt(a-b)-c} instead of {\tt a-(b-c)}.)
Precedence is determined by order of appearance: tokens
in the same declaration are at the same level of precedence;
tokens declared later are of higher precedence. In this way
the grammar proper is ambiguous (that is, there are multiple
ways to parse some inputs), but the extra information in the
declarations resolves the ambiguity.

The rest of the code is the routines in the second half of the
file {\tt hoc.y}:
\begincode
~                       \it Continuing\/\tt hoc.y
char    *progname;       /* for error messages */
int     lineno = 1;
\medskip
int main(int argc, char *argv[])   /* hoc1 */
{
~       progname = argv[0];
~       yyparse();
~       return 0;
}
\endcode
\noindent
{\tt main} calls {\tt yyparse} to parse the input. Looping from
one expression to the next is done entirely within the grammar,
by the sequence of productions for {\tt list}. It would have been
equally acceptable to put a loop around the call to {\tt yyparse}
in {\tt main} and have the action for {\tt list} print the value
and return immediately.

{\tt yyparse} in turn calls {\tt yylex} repeatedly for input
tokens. Our {\tt yylex} is easy: it skips blanks and tabs,
converts strings of digits into a numeric value, counts input
lines for error reporting, and returns any other character as
itself.
Since the grammar expects to see only {\tt+}, {\tt-}, {\tt*},
{\tt/}, {\tt(}, {\tt)}, and {\tt\\n}, any other character
will cause {\tt yyparse} to report an error. Returning a {\tt0}
signals ``end of file'' to {\tt yyparse}.
\begincode
~                       \it Continuing\/\tt hoc.y
int yylex(void)          /* hoc1 */
{
~       int c;
\smallskip
~       while ((c=getchar()) == ' ' || c == '\\t')
~               ;
~       if (c == EOF)
~               return 0;
~       if (c == '.' || isdigit(c)) {   /* number */
~               ungetc(c, stdin);
~               scanf("%lf", &yylval);
~               return NUMBER;
~       }
~       if (c == '\\n')
~               lineno++;
~       return c;
}
\endcode
\noindent
The variable {\tt yylval} is used for communication between
the parser and the lexical analyzer; it is defined by {\tt yyparse},
and has the same type as the {\tt yacc} stack. {\tt yylex} returns
the {\it type\/} of a token as its function value, and sets
{\tt yylval} to the {\it value\/} of the token (if there is one).
For instance, a floating point number has the type {\tt NUMBER}
and a value like 12.34. For some tokens, especially single
characters like {\tt'+'} and {\tt'\\n'}, the grammar does not use
the value, only the type. In that case, {\tt yylval} need not be set.

The {\tt yacc} declaration {\tt\%token NUMBER} is converted into
a {\tt\#define} statement in the {\tt yacc} output file {\tt y.tab.c},
so {\tt NUMBER} can be used as a constant anywhere in the C program.
{\tt yacc} chooses values that won't collide with {\sc ASCII} characters.

If there is a syntax error, {\tt yyparse} calls {\tt yyerror} with
a string containing the cryptic message ``{\tt syntax error}.''
The {\tt yacc} user is expected to provide a {\tt yyerror}; ours
just passes the string on to another function, {\tt warning},
which prints somewhat more information. Later versions of {\tt hoc}
will make direct use of {\tt warning}.

\begincode
void yyerror(char *s)  /* called for yacc syntax error */
{
~       warning(s, 0);
}
\medbreak
void warning(char *s, char *t)  /* print warning message */
{
~       fprintf(stderr, "%s: %s", progname, s);
~       if (t) fprintf(stderr, " %s", t);
~       fprintf(stderr, " near line %d\\n", lineno);
}
\endcode

\noindent
This marks the end of the routines in {\tt hoc.y}.

Compilation of a {\tt yacc} program is a two-step process:
\begincode
$ yacc hoc.y            \it Leaves output in \tt y.tab.c
$ cc y.tab.c -o hoc1    \it Leaves executable program in \tt hoc1
$ hoc1
2/3
~       0.66666667
-3-4
hoc1: syntax error near line 1
$
\endcode

\exercise 8-1.
Examine the structure of the {\tt y.tab.c} file.
%(It's about 300 lines long for {\tt hoc1}.)
\endexercise

\subsect Making changes---unary minus.
We claimed earlier that using {\tt yacc} makes it easy to change
a language. As an illustration, let's add unary minus to {\tt hoc1},
so that expressions like {\tt-3-4} are evaluated, not rejected
as syntax errors.

Exactly two lines have to be added to {\tt hoc.y}. A new token
{\tt UNARYMINUS} is added to the end of the precedence section,
to make unary minus have highest precedence:
\begincode
%left  '+' '-'
%left  '*' '/'
%left  UNARYMINUS      /* new */
\endcode
\noindent
The grammar is augmented with one more production for {\tt expr}:
\begincode
expr:    NUMBER                      { $$ = $1; }
~      | '-' expr  %prec UNARYMINUS  { $$ = -$2; }  /* new */
\endcode
\noindent
The {\tt\%prec} says that a unary minus sign (that is, a minus
sign before an expression) has the precedence of {\tt UNARYMINUS}
(high); the action is to change the sign. A minus sign between
two expressions takes the default precedence.

\exercise 8-2.
Add the operators {\tt\%} (modulus or remainder) and unary {\tt+}
to {\tt hoc1}. Suggestion: look at {\tt frexp}(3) [or rather
{\tt fmod}(3)].\endexercise

\subsect A digression on {\tt make}.
It's a nuisance to have to type two commands to compile a new
version of {\tt hoc1}. Although it's certainly easy to make a
shell file that does the job, there's a better way, one that
will generalize nicely later on when there is more than one
source file in the program. The program {\tt make} reads a
specification of how the components of a program depend on
each other, and how to process them to create an up-to-date
version of the program. It checks the times at which the
various components were last modified, figures out the
minimum amount of recompilation that has to be done to make
a consistent new version, then runs the processes. {\tt make}
also understands the intricacies of multi-step processes like
{\tt yacc}, so these tasks can be put into a {\tt make}
specification without spelling out the individual steps.

{\tt make} is most useful when the program being created
is large enough to be spread over several source files,
but it's handy even for something as small as {\tt hoc1}.
Here is the {\tt make} specification for {\tt hoc1}, which
{\tt make} expects in a file called {\tt Makefile} or
{\tt makefile}.
\begincode
hoc1: hoc.o
~       $(CC) $(CFLAGS) hoc.o -o hoc1
\endcode
\noindent
The second line is indented with a tab, not with blanks!
This makefile says that {\tt hoc1} depends on {\tt hoc.o}, and
that {\tt hoc.o} is converted into {\tt hoc1} by running the
C~compiler and putting the output in {\tt hoc1}.
{\tt make} already knows how to convert the {\tt yacc} source
file in {\tt hoc.y} to an object file {\tt hoc.o}:
\begincode
$ make                 \it Make the first thing in\tt Makefile\it,\tt hoc1
yacc hoc.y
cc -c y.tab.c
rm y.tab.c
mv y.tab.o hoc.o
cc hoc.o -o hoc1
$ make                 \it Do it again\tt
`hoc1' is up to date.   make\it realizes it's unnecessary\tt
$
\endcode


\section Stage 2: Variables and error recovery

The next step (a small one) is to add ``memory'' to {\tt hoc1},
to make {\tt hoc2}. The memory has 26 variables, named {\tt a}
to {\tt z}. This isn't very elegant, but it's an easy and useful
intermediate step. We'll also add some error handling. If you
try {\tt hoc1}, you'll recognize that its approach to syntax
errors is to print a message and die, and its treatment of
arithmetic errors like division by zero is reprehensible:

\begincode
$ hoc1
1/0
Floating exception - core dumped
$
\endcode

The changes needed for these new features are modest, about
35~lines of code. The lexical analyzer {\tt yylex} has to
recognize letters as variables; the grammar has to include
productions of the form
\begincode
expr:   VAR
~     | VAR '=' expr
\endcode
\noindent
An expression can contain an assignment, which permits multiple
assignments like
\begincode
x = y = z = 0
\endcode

The easiest way to store the values of the variables is in a
26-element array; the single-letter variable name can be used
to index the array. But if the grammar is to process both
variable names and values in the same stack, {\tt yacc} has
to be told that its stack contains a union of a {\tt double}
and an {\tt int}, not just a {\tt double}. This is done with
the {\tt\%union} declaration near the top. A {\tt\#define}
or a {\tt typedef} is fine for setting the stack to a basic
type like {\tt double}, but the {\tt\%union} mechanism is
required for union types because {\tt yacc} checks for
consistency in expressions like {\tt\$\$=\$2}.

Here is the grammar part of {\tt hoc.y} for {\tt hoc2}:
\begincode
%{
double mem[26];          /* memory for variables 'a' to 'z' */
%}
%union {
~       double  val;     /* actual value */
~       int     index;   /* index into mem[] */
}
%token  <val>   NUMBER
%token  <index> VAR      /* VAR is index member of union */
%type   <val>   expr     /* expr is val member of union */
%right  '='
%left   '+' '-'
%left   '*' '/'
%left   UNARYPM
%%
list:     /* nothing */
~       | list '\\n'
~       | list expr '\\n'      { printf("\\t%.8g\\n", $2); }
~       | list error '\\n'     { yyerrok; }
~       ;
expr:     NUMBER
~       | VAR            { $$ = mem[$1]; }
~       | VAR '=' expr   { $$ = mem[$1] = $3; }
~       | expr '+' expr  { $$ = $1 + $3; }
~       | expr '-' expr  { $$ = $1 - $3; }
~       | expr '*' expr  { $$ = $1 * $3; }
~       | expr '/' expr  { if ($3 == 0.0)
~                            execerror("division by zero", "");
~                          $$ = $1 / $3; }
~       | '(' expr ')'   { $$ = $2; }
~       | '-' expr  %prec UNARYPM  { $$ = -$2; }
~       ;
%%
~       /* end of grammar */
...
\endcode

\noindent
The {\tt\%union} says that stack elements hold either a
{\tt double} (a number, the usual case), or an {\tt int},
which is an index into the array {\tt mem}. The {\tt\%token}
declarations have been augmented with a type indicator.
The {\tt\%type} declaration specifies that {\tt expr} is the
{\tt<val>} member of the union, i.e., a {\tt double}.
The type information makes it possible for {\tt yacc}
to generate references to the corect members of the union.
Notice also that {\tt=} is right-associative, while the
other operators are left-associative.

Error handling comes in several pieces. The obvious one is
a test for a zero divisor; if one occurs, an error routine
{\tt execerror} is called.

A second test is to catch the ``floating point exception''
signal that occurs when a floating point number overflows.
The signal is set in {\tt main}.

The final part of error recovery is the addition of a
production for {\tt error}. ``{\tt error}'' is a reserved
word in a {\tt yacc} grammar; it provides a way to anticipate
and recover from a syntax error. If an error occurs, {\tt yacc}
will eventually try to use this production, recognize the
error as grammatically ``correct,'' and thus recover.
The action {\tt yyerrok} sets a flag in the parser that
permits it to get back into a sensible parsing state.
Error recovery is difficult in any parser; you should be aware
that we have taken only the most elementary steps here, and
have skipped rapidly over {\tt yacc}'s capabilities as well.

The actions in the {\tt hoc2} grammar are not much changed.
Here is {\tt main}, to which we have added {\tt setjmp} to
save a clean state suitable for resuming after an error.
{\tt execerror} does the matching {\tt longjmp}.
\begincode
...
#include <signal.h>
#include <setjmp.h>
jmp_buf begin;
\medskip
int main(int argc, char *argv[])  /* hoc2 */
{
~       void fpecatch(int);
\medskip
~       progname = argv[0];
~       setjmp(begin);
~       signal(SIGFPE, fpecatch);
~       yyparse();
~       return 0;
}
\medskip
void execerror(char *s, char *t)  /* run-time error recovery */
{
~       warning(s, t);
~       longjmp(begin, 0);
}
\medskip
void fpecatch(int signum)  /* catch floating point exceptions */
{
~       execerror("floating point exception", (char *) 0);
}
\endcode
\noindent
For debugging, we found it convenient to have {\tt execerror} call
{\tt abort}(3), which causes a core dump that can be perused with
{\tt adb} or {\tt sdb} [or {\tt gdb}]. Once the program
is fairly robust, {\tt abort} is replaced by {\tt longjmp}.

The lexical analyzer is a little different in {\tt hoc2}.
There is an extra test for a lower-case letter, and since
{\tt yylval} is now a union, the proper member has to be set
before {\tt yylex} returns. Here are the parts that have changed:
\begincode
int yylex(void)  /* hoc2 */
...
~       if (c == '.' || isdigit(c)) {  /* number */
~               ungetc(c, stdin);
~               scanf("%lf", &yylval.val);
~               return NUMBER;
~       }
~       if (islower(c)) {
~               yylval.index = c - 'a';  /* ASCII only */
~               return VAR;
~       }
...
\endcode
\noindent
Again, notice how the token type (e.g., {\tt NUMBER}) is distinct
from its value (e.g., 3.1416);

Let us illustrate variables and error recovery, the new
things in {\tt hoc2}:
\begincode
$ hoc2
x = 355
~       355
y = 113
~       113
p = x/z                         \it z is undefined and thus zero\tt
hoc2: division by zero near line 4     \it Error recovery\tt
x/y
~       3.1415929
1e30 * 1e30                            \it Overflow\tt
hoc2: floating point exception near line 5
...
\endcode
\noindent
Actually, the {\sc PDP}-11 requires special arrangements to detect
floating point overflow, but on most other machines {\tt hoc2}
behaves as shown.

\exercise 8-3.
Add a facility for remembering the most recent value computed,
so that it does not have to be retyped in a sequence of related
computations. One solution is to make it one of the variables,
for instance `{\tt p}' for `previous.'\endexercise

\exercise 8-4.
Modify {\tt hoc} so that a semicolon can be used as an expression
terminator equivalent to a newline.\endexercise


\section Stage 3: Arbitrary variable names; built-in functions

This version, {\tt hoc3}, adds several major new capabilities,
and a corresponding amount of extra code. The main feature is
access to built-in functions:
\begincode
sin   cos   atan   exp   log   log10   sqrt   int   abs
\endcode
\noindent
We have also added an exponentiation operator `{\tt\char"5E}'; it has
the highest precendence, and is right-associative.

Since the lexical analyzer has to cope with built-in names
longer than a single character, it isn't much extra effort
to permit variable names to be arbitrarily long as well.
We will need a more sophisticated symbol table to keep track
of these variables, but once we have it, we can pre-load it
with names and values for some useful constants:
\medskip
\halign{\tabskip1em\indent\tt#\hfil&#\hfil&#\hfil\cr
  DEG&     57.29577951308232087680& $180/\pi$, degrees per radian\cr
  E&      \02.71828182845904523536& $e$, base of natural logarithms\cr
  GAMMA&  \00.57721566490153286060& $\gamma$, Euler-Mascheroni constant\cr
  PHI&    \01.61803398874989484820& $(\sqrt 5+1)/2$, the golden ratio\cr
  PI&     \03.14159265358979323846& $\pi$, circular transcendental number\cr}
\medbreak
\noindent
The result is a useful calculator:
\begincode
$ hoc3
1.5^2.3
~       2.5410306
exp(2.3*log(1.5))
~       2.5410306
sin(PI/2)
~       1
atan(1)*DEG
~       45
...
\endcode

We have also cleaned up the behavior a little. In {\tt hoc2},
the assignment {\tt x=\it expr\/} not only causes the assignment
but also prints the value, because all expressions are printed:
\begincode
$ hoc2
x = 2 * 3.14159
~       6.28318        \it Value printed for assignment to variable\tt
\endcode
\noindent
In {\tt hoc3}, a distinction is made between assignments and
expressions; values are printed only for expressions:
\begincode
$ hoc3
x = 2 * 3.14159        \it Assignment: no value is printed\tt
x                      \it Expression:\tt
~       6.28318        \it\quad value is printed
\endcode

The program that results from all these changes is big enough
(about 250 lines) that it is best split into separate files
for easier editing and faster compilation.
There are now five files instead of one:
\medskip
\halign{\tabskip2em\indent\tt#\hfil&#\hfil\cr
  hoc.y&    Grammar, {\tt main}, {\tt yylex} (as before)\cr
  hoc.h&    Global data structures for inclusion\cr
  symbol.c& Symbol table routines: {\tt lookup}, {\tt install}\cr
  init.c&   Built-ins and constants: {\tt init}\cr
  math.c&   Interfaces to math routines: {\tt Sqrt}, {\tt Log}, etc.\cr}
\medskip
\noindent
This requires that we learn more about how to organize
a multi-file C program, and more about {\tt make} so it can
do some of the work for us.

We'll get back to {\tt make} shortly. First, let us look at
the symbol table code. A symbol has a name, a type (it's
either a {\tt VAR} or a {\tt BLTIN}), and a value. If the
symbol is a {\tt VAR}, the value is a {\tt double}; if the
symbol is a built-in, the value is a pointer to a function
that returns a {\tt double}. This information is needed in
{\tt hoc.y}, {\tt symbol.c}, and {\tt init.c}. We could just
make three copies, but it's too easy to make a mistake or
forget to update one copy when a change is made. Instead
we put the common information into a header file {\tt hoc.h}
that will be included by any file that needs it. (The suffix
{\tt.h} is conventional but not enforced by any program.)
We will also add to the {\tt Makefile} the fact that these
files depend on {\tt hoc.h}, so that when it changes, the
necessary recompilations are done too. Here is {\tt hoc.h}:
\begincode
struct Symbol {            /* symbol table entry */
~       char    *name;
~       short   type;            /* VAR, BLTIN, UNDEF */
~       union {
~               double  val;            /* if VAR */
~               double  (*ptr)();       /* if BLTIN */
~       } u;
~       struct Symbol   *next;   /* to link to another */
} Symbol;
\smallskip
typedef struct Symbol Symbol;
\smallskip
Symbol *install(char *s, int t, double d);
Symbol *lookup(char *s);
\smallskip
void init(void);
void execerror(char *s, char *t);
\endcode
\noindent
The type {\tt UNDEF} is a {\tt VAR} that has not yet been
assigned a value.

The symbols are linked together in a list using the {\tt next}
field in {\tt Symbol}. The list itself is local to {\tt symbol.c};
the only access to it is through the functions {\tt lookup} and
{\tt install}. This makes it easy to change the symbol table
organization if it becomes necessary. (We did that once.)
{\tt lookup} searches the list for a particular name and returns
a pointer to the {\tt Symbol} with that name if found, and zero
otherwise. The symbol table uses linear search, which is entirely
adequate for our interactive calculator, since variables are looked
up only during parsing, not execution. {\tt install} puts a variable
with its associated type and value at the head of the list.
{\tt emalloc} calls {\tt malloc}(3), the standard storage allocator,
and checks the result. These three routines are the contents of
{\tt symbol.c}. The file {\tt y.tab.h} is generated by running
{\tt yacc -d}; it contains {\tt\#define} statements that {\tt yacc}
has generated for tokens like {\tt NUMBER}, {\tt VAR}, {\tt BLTIN},
etc. Here is {\tt symbol.c}:
\begincode
#include "hoc.h"
#include "y.tab.h"
#include <stdlib.h>
#include <string.h>
\medskip
void *emalloc(unsigned nbytes);
\medskip
static Symbol *symlist = 0;  /* symbol table: linked list */
\medskip
Symbol *lookup(char *s)  /* find s in symbol table */
{
~       Symbol *sp;
~       for (sp = symlist; sp; sp = sp->next)
~               if (strcmp(sp->name, s) == 0)
~                       return sp;
~       return 0;  /* not found */
}
\medbreak
Symbol *install(char *s, int t, double d)  /* add s to symtab */
{
~       Symbol *sp = emalloc(sizeof(Symbol));
~       sp->name = emalloc(strlen(s)+1);  /* +1 for '\\0' */
~       strcpy(sp->name, s);
~       sp->type = t;
~       sp->u.val = d;
~       sp->next = symlist;  /* put at front of list */
~       symlist = sp;
~       return sp;
}
\medbreak
void *emalloc(unsigned nbytes)  /* check return from malloc */
{
~       void *p = malloc(nbytes);
~       if (!p) execerror("out of memory", 0);
~       return p;
}
\endcode

The file {\tt init.c} contains definitions for the constants
({\tt PI}, etc.) and function pointers for built-ins; they are
installed in the symbol table by the function {\tt init},
which is called by {\tt main}. Here is {\tt init.c}:
\begincode
#include "hoc.h"
#include "y.tab.h"
#include <math.h>
\medskip
extern double Log(), Log10(), Exp(), Sqrt(), integer();
\medbreak
static struct {        /* Constants */
~   char    *name;
~   double  cval;
} consts[] = {
~   { "PI",    3.14159265358979323846 },
~   { "E",     2.71828182845904523536 },
~   { "GAMMA", 0.57721566490153286060 },  /* Euler */
~   { "DEG",  57.29577951308232087680 },  /* deg/radian */
~   { "PHI",   1.61803398874989484820 },  /* golden ratio */
~   { 0,       0 }
};
\medbreak
static struct {        /* Built-ins */
~   char    *name;
~   double  (*func)();
} builtins[] = {
~   { "sin",    sin     },
~   { "cos",    cos     },
~   { "atan",   atan    },
~   { "log",    Log     },  /* checks argument */
~   { "log10",  Log10   },  /* checks argument */
~   { "exp",    Exp     },  /* checks argument */
~   { "sqrt",   Sqrt    },  /* checks argument */
~   { "int",    integer },
~   { "abs",    fabs    },
~   { 0,        0       }
};
\medbreak
void init(void)  /* install constants and built-ins in symtab */
{
~       int i;
~       Symbol *sp;
\smallbreak
~       for (i = 0; consts[i].name; i++)
~               install(consts[i].name, VAR, consts[i].cval);
~       for (i = 0; builtins[i].name; i++) {
~               sp = install(builtins[i].name, BLTIN, 0.0);
~               sp->u.ptr = builtins[i].func;
~       }
}
\endcode
\noindent
The data is kept in tables rather than being wired into the
code because tables are easier to read and to change. The tables
are declared {\tt static} so that they are visible only within
this file rather than throughout the program. We'll come back
to the math routines like {\tt Log} and {\tt Sqrt} shortly.

With the foundation in place, we can move on to the changes
in the grammar that make use of it. Here is {\tt hoc.y}:
\begincode
%{
#include "hoc.h"
extern double Pow();
%}
%union {
~       double  val;    /* actual value */
~       Symbol *sym;    /* symbol table pointer */
}
%token  <val>   NUMBER
%token  <sym>   VAR BLTIN UNDEF
%token  <val>   expr asgn
%right  '='
%left   '+' '-'
%left   '*' '/'
%left   UNARYPM
%right  '^'     /* exponentiation */
%%
list:     /* nothing */
~       | list       '\\n'
~       | list asgn  '\\n'
~       | list expr  '\\n'    { printf("\\t%.8g\\n", $2); }
~       | list error '\\n'    { yyerrok; }
~       ;
asgn:     VAR '=' expr  { $$ = $1->u.val = $3; $1->type = VAR; }
~       ;
expr:     NUMBER
~       | VAR { if ($1->type == UNDEF)
~                   execerror("undefined variable", $1->name);
~               $$ = $1->u.val; }
~       | asgn
~       | BLTIN '(' expr ')'  { $$ = (*($1->u.ptr))($3); }
~       | expr '+' expr  { $$ = $1 + $3; }
~       | expr '-' expr  { $$ = $1 - $3; }
~       | expr '*' expr  { $$ = $1 * $3; }
~       | expr '/' expr  { if ($3 == 0.0)
~                              execerror("division by zero", "");
~                          $$ = $1 / $3; }
~       | expr '^' expr  { $$ = Pow($1, $3); }
~       | '(' expr ')'   { $$ = $2; }
~       | '-' expr  %prec UNARYPM  { $$ = -$2; }
~       | '+' expr  %prec UNARYPM  { $$ = $2; }
~       ;
%%
~       /* end of grammar */
...
\endcode
\noindent
The grammar now has {\tt asgn}, for assignment, as well as
{\tt expr}; an input line that contains just
\begincode
VAR = expr
\endcode
\noindent
is an assignment, and so no value is printed. Notice, by the way,
how easy it was to add exponentiation to the grammar, including
its right associativity.

The {\tt yacc} stack has a different {\tt\%union}: instead of
referring to a variable by its index in a 26-element table,
there is a pointer to an object of type {\tt Symbol}. The
header file {\tt hoc.h} contains the definition of thi stype.

The lexical analyzer recognizes variable names, looks them up
in the symbol table, an ddecides whether they are variables
({\tt VAR}) or built-ins ({\tt BLTIN}). The type returned by
{\tt yylex} is one of these; both user-defined variables and
pre-defined variables like {\tt PI} are {\tt VAR}'s.

One of the properties of a variable is whether or not it has
been assigned a value, so the use of an undefined variable
can be reported as an error by {\tt yyparse}. The test for
whether a variable is defined has to be in the grammar, not
in the lexical analyzer. When a {\tt VAR} is recognized lexically,
its context isn't yet known; we don't want a complaint that {\tt x}
is undefined when the context is a perfectly legal one such as the
left side of an assignment like {\tt x=1}.

Here is the revised part of {\tt yylex}:
\begincode
int yylex(void)  /* hoc3 */
...
~       if (isalpha(c)) {
~               Symbol *sp;
~               char sbuf[100], *p = sbuf;
~               do {
~                       *p++ = c;
~               } while ((c=getchar()) != EOF && isalnum(c));
~               ungetc(c, stdin);
~               *p = '\\0';
~               if ((sp=lookup(sbuf)) == 0)
~                       sp = install(sbuf, UNDEF, 0.0);
~               yylval.sym = sp;
~               return sp->type == UNDEF ? VAR : sp->type;
~       }
...
\endcode

{\tt main} has one extra line, which calls the initialization
routine {\tt init} to install built-ins and pre-defined names
like {\tt PI} in the symbol table. Here it is:
\begincode
int main(int argc, char *argv[])  /* hoc3 */
{
~       void fpecatch(int);
\smallskip
~       progname = argv[0];
~       init();
~       setjmp(begin);
~       signal(SIGFPE, fpecatch);
~       yyparse();
~       return 0;
}
\endcode

The only remaining file is {\tt math.c}. Some of the standard
mathematical functions need an error-checking interface for
messages and recovery---for example the standard function
{\tt sqrt} silently returns zero if its argument is negative.
The code in {\tt math.c} uses the error tests found in Section~2
of the {\sl UNIX Programmer's Manual}. This is more reliable
and portable than writing our own tests, since presumably the
specific limitations of the routines are best reflected in the
``official'' code. The header file {\tt<math.h>} contains type
declarations for the standard mathematical functions.
{\tt<errno.h>} contains names for the errors that can be incurred.
Here is {\tt math.c}:
\begincode
#include "hoc.h"
#include <math.h>
#include <errno.h>
\smallskip
double errcheck(double d, char *s);
\smallbreak
double Log(double x)   { return errcheck(log(x),   "log");   }
double Log10(double x) { return errcheck(log10(x), "log10"); }
double Exp(double x)   { return errcheck(exp(x),   "exp");   }
double Sqrt(double x)  { return errcheck(sqrt(x),  "sqrt");  }
double Pow(double x, double y) {
~                        return errcheck(pow(x,y), "pow");   }
\smallbreak
double integer(double x) { return (double)(long) x; }
\smallbreak
double errcheck(double d, char *s)
{ /* check result of library call */
~       if (errno == EDOM) {
~               errno = 0;
~               execerror(s, "argument out of domain");
~       } else if (errno == ERANGE) {
~               errno = 0;
~               execerror(s, "result out of range");
~       }
~       return d;
}
\endcode

An interesting (and ungrammatical) diagnostic appears when
we run {\tt yacc} on the new grammar:
\begincode
$ yacc hoc.y
conflicts: 1 shift/reduce
$
\endcode
\noindent
The ``shift/reduce'' message means that the {\tt hoc3} grammar
is ambiguous: the single line of input
\begincode
x = 1
\endcode
\noindent
can be parsed in two ways:
\medskip
\centerline{\epsfbox{unixdev-2.mps}\hfil\epsfbox{unixdev-3.mps}}
\medskip
\noindent
The parser can decide that the {\it asgn\/} should be reduced to
an {\it expr\/} and then to a {\it list}, as in the parse tree on
the left, or it can decide to use the following {\tt\\n} immediately
(``shift'') and convert the whole thing to a {\it list\/} without
the intermediate rule, as in the tree on the right. Given the
ambiguity, {\tt yacc} chooses to shift, since this is almost always
the right thing to do with real grammars. You should try to understand
such messages, to be sure that {\tt yacc} has made the right decision.%
\footnote{$\dag$}{\ninepoint The {\tt yacc} message ``reduce/reduce
conflict'' indicates a serious problem, more often the symptom of an
outright error in the grammar than an intentional ambiguity.}
Running {\tt yacc} with the option {\tt-v} produces a voluminous
file called {\tt y.output} that hints at the origin of conflicts.

\exercise 8-5.
As {\tt hoc3} stands, it's legal to say {\tt PI = 3}. Is this a good
idea? How would you change {\tt hoc3} to prohibit assignment to
``constants''?\endexercise

\exercise 8-6.
Add the built-in function {\tt atan2(y,x)}, which returns the angle
whose tangent is {\tt y/x}. Add the built-in {\tt rand()}, which
returns a floating point random variable uniformly distributed on
the interval $(0,1)$. How do you have to change the grammar to allow
for built-ins with different numbers of arguments?\endexercise

\exercise 8-7.
How would you add a facility to execute commands from within {\tt hoc},
similar to the {\tt!}~feature of other {\sc UNIX} programs?\endexercise

\exercise 8-8.
Revise the code in {\tt math.c} to use a table instead of the set
of essentially identical functions that we presented.\endexercise

\subsect Another digression on {\tt make}.
Since the program for {\tt hoc3} now lives on five files, not one,
the {\tt Makefile} is more complicated:
\begincode
YFLAGS = -d                   # force creation of y.tab.h
OBJS = hoc.o init.o math.o symbol.o        # abbreviation
\medskip
hoc3: $(OBJS)
~       $(CC) $(OBJS) -lm -o hoc3
\medskip
hoc.o: hoc.h
\medskip
init.o symbol.o: hoc.h y.tab.h
\medskip
pr:
~       @pr hoc.y hoc.h init.c math.c symbol.c Makefile
\medskip
clean:
~       rm -f $(OBJS) y.tab.[ch]
\endcode
\noindent
The {\tt YFLAGS\kern.5ex=\kern.5ex-d} line adds the option {\tt-d}
to the {\tt yacc} command line generated by {\tt make}; this tells
{\tt yacc} to produce the {\tt y.tab.h} file of {\tt\#define} statements.
The {\tt OBJS\kern.5ex=\kern.5ex\rm...} line defines a shorthand for a
construct to be used several times subsequently. The syntax is not the
same as for shell variables---the parentheses are mandatory. The flag
{\tt -lm} causes the math library to be searched for the mathematical
functions.

{\tt hoc3} now depends on four {\tt.o} files; some of the {\tt.o} files
depend on {\tt.h} files. Given these dependencies, {\tt make} can deduce
what recompilation is needed after changes are made to any of the files
involved. If you want to see what {\tt make} will do without actually
running the processes, try
\begincode
$ make -n
\endcode
\noindent
On the other hand, if you want to force the file times into a consistent
state, the {\tt-t} (``touch'') option will update them without doing
any compilation steps.

Notice that we have added not only a set of dependencies for the
source files but miscellaneous utility routines as well, all neatly
encapsulated in one place. By default, {\tt make} makes the first
thing listed in the {\tt Makefile}, but if you name an item that
labels a dependency rule, like {\tt symbol.o} or {\tt pr}, that
will be made instead. An empty dependency is taken to mean that
the item is never ``up to date,'' so that action will always be done
when requested. Thus
\begincode
$ make pr | lpr
\endcode
\noindent
produces the listing you asked for on a line printer. (The leading
{\tt @} in ``{\tt @pr}'' suppresses the echo of the command being
executed by {\tt make}.) And
\begincode
$ make clean
\endcode
\noindent
removes the {\tt yacc} output files and the {\tt.o} files.

This mechanism of empty dependencies in the {\tt Makefile} is
often preferable to a shell file as a way to keep all the related
computations in a single file. And {\tt make} is not restricted
to program development---it is valuable for packaging any set of
operations that have time dependencies.

\subsect A digression on {\tt lex}.
The program {\tt lex} creates lexical analyzers in a manner analogous
to the way that {\tt yacc} creates parsers: you write a specification
of the lexical rules of your language, using regular expressions and
fragments of C to be executed when a matching string is found.
{\tt lex} translates that into a recognizer. {\tt lex} and {\tt yacc}
cooperate by the same mechanism as the lexical analyzers we have
already written. We are not going into great detail on {\tt lex} here;
the following discussion is mainly to interest you in learning more.
%See the reference manual for {\tt lex} in Volume~2B of the {\sl UNIX
%Programmer's Manual}.

First, here is the {\tt lex} program, from the file {\tt lex.l};
it replaces the function {\tt yylex} that we have used so far.
\begincode
%{
#include "hoc.h"
#include "y.tab.h"
extern int lineno;
%}
%%
[ \\t]   { ; }   /* skip blanks and tabs */
[0-9]+\\.?|[0-9]*\\.[0-9]+ {
~       sscanf(yytext, "%lf", &yylval.val); return NUMBER; }
[a-zA-Z][a-zA-Z0-9]* {
~       Symbol *s;
~       if ((s = lookup(yytext)) == 0)
~               s = install(yytext, UNDEF, 0.0);
~       yylval.sym = s;
~       return s->type == UNDEF ? VAR : s->type; }
\\n      { lineno++; return '\\n'; }
.       { return yytext[0]; }   /* everything else */
\endcode
\noindent
Each ``rule'' is a regular expression like those in {\tt egrep}
or {\tt awk}, except that {\tt lex} recognizes C-style escapes
like {\tt\\t} and {\tt\\n}. The action is enclosed in braces.
The rules are attempted in order, and constructs like {\tt*}
and {\tt+} match as long a string as possible. If the rule matches
the next part of the input, the action is performed. The input
string that matched is accessible in a {\tt lex} string called
{\tt yytext}.

The {\tt Makefile} has to be changed to use {\tt lex}:
\begincode
YFLAGS = -d
OBJS = hoc.o lex.o init.o math.o symbol.o
\medskip
hoc3: $(OBJS)
~       $(CC) $(OBJS) -lm -ll -o hoc3
\medskip
hoc.o: hoc.h
\medskip
lex.o init.o symbol.o: hoc.h y.tab.h
...
\endcode
\noindent
Again, {\tt make} knows how to get from a {\tt.l} file to the
proper {\tt.o}; all it needs from us is the dependency information.
(We also have to add the {\tt lex} library {\tt-ll} to the list
searched by {\tt cc} since the {\tt lex}-generated recognizer
is not self-contained.) The output is spectacular and completely
automatic:
\begincode
$ make
yacc -d hoc.y
conflicts: 1 shift/reduce
cc  -c y.tab.c
rm y.tab.c
mv y.tab.o hoc.o
lex  lex.l
cc  -c lex.yy.c
rm lex.yy.c
mv lex.yy.o lex.o
cc  -c init.c
cc  -c math.c
cc  -c symbol.c
cc hoc.o lex.o init.o math.o symbol.o -lm -ll -o hoc3
$
\endcode

If a signle file is changed, the single command {\tt make} is
enough to make an up-to-date version:
\begincode
$ touch lex.l               \it Change modified-time of \tt lex.l
$ make
lex  lex.l
cc  -c lex.yy.c
rm lex.yy.c
mv lex.yy.o lex.o
cc hoc.o lex.o init.o math.o symbol.o -lm -ll -o hoc3
$
\endcode

We debated for quite a while whether to treat {\tt lex} as a
digression, to be illustrated briefly and then dropped, or as
the primary tool for lexical analysis once the language got
complicated. There are arguments on both sides. The main problem
with {\tt lex} (aside from requiring that the user learn yet
another language) is that it tends to be slow to run and to
produce bigger and slower recognizers than the equivalent C
versions. It is also somewhat harder to adapt its input mechanism
if one is doing anything unusual, such as error recovery or
even input from files. None of these issues is serious in the
context of {\tt hoc}. The main limitation is space: it takes
more pages to describe the {\tt lex} version, so (regretfully)
we will revert to C for subsequent lexical analysis. It is a
good exercise to do the {\tt lex} versions, however.

\exercise 8-9.
Compare the sizes of the two versions of {\tt hoc3}.
Hint: see {\tt size}(1).\endexercise

\bye
